
  deepdive.db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user: ${PGUSER}
    password: ${PGPASSWORD}
    dbname: ${DBNAME}
    host: ${PGHOST}
    port: ${PGPORT}
    incremental_mode: ORIGINAL
    }
    


      deepdive.schema.variables {
        pheno_mentions_filtered_inference.label: Boolean
genevariant_relations_inference.label: Boolean
genepheno_causation_inference.label: Boolean
genepheno_association_inference.label: Boolean
gene_mentions_filtered_inference.label: Boolean
non_gene_acronyms_inference.label: Boolean
      }
    

          deepdive.extraction.extractors.extraction_rule_83 {
            sql: """ DROP TABLE IF EXISTS genevariant_coding_supervise_true CASCADE;
            CREATE TABLE
            genevariant_coding_supervise_true(doc_id text,
                                 mention_id text,
                                 entity text,
                                 pos text,
                                 fromseq text,
                                 toseq text,
                                 gene_names text[])
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_85 {
            sql: """ DROP TABLE IF EXISTS gene_mentions_filtered CASCADE;
            CREATE TABLE
            gene_mentions_filtered(id bigint,
                      doc_id text,
                      section_id text,
                      sent_id integer,
                      wordidxs text,
                      mention_id text,
                      mapping_type text,
                      supertype text,
                      subtype text,
                      gene_name text,
                      words text,
                      is_correct boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_0 {
            sql: """ DROP TABLE IF EXISTS sentences CASCADE;
            CREATE TABLE
            sentences(doc_id text,
         section_id text,
         sent_id int,
         ref_doc_id text,
         words text[],
         lemmas text[],
         poses text[],
         ners text[],
         dep_paths text[],
         dep_parents int[])
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_40 {
            sql: """ DROP TABLE IF EXISTS genevariant_relations_inference CASCADE;
            CREATE TABLE
            genevariant_relations_inference(relation_id text,
                               id bigint,
                               label boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_3 {
            sql: """ DROP TABLE IF EXISTS genes CASCADE;
            CREATE TABLE
            genes(ensembl_id text,
     canonical_name text,
     gene_name text,
     name_type text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_6 {
            sql: """ DROP TABLE IF EXISTS gene_features CASCADE;
            CREATE TABLE
            gene_features(doc_id text,
             section_id text,
             mention_id text,
             feature text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_37 {
            sql: """ DROP TABLE IF EXISTS genepheno_association_inference CASCADE;
            CREATE TABLE
            genepheno_association_inference(relation_id text,
                               id bigint,
                               label boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_19 {
            sql: """ DROP TABLE IF EXISTS pheno_acronyms CASCADE;
            CREATE TABLE
            pheno_acronyms(id bigint,
              doc_id text,
              section_id text,
              sent_id int,
              short_wordidxs int[],
              long_wordidxs int[],
              mention_id text,
              supertype text,
              subtype text,
              abbrev text,
              definition text[],
              entity text,
              is_correct boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_31 {
            sql: """ DROP TABLE IF EXISTS ensembl_protein_sequences CASCADE;
            CREATE TABLE
            ensembl_protein_sequences(ensembl_transcript text,
                         aa_seq text[])
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_30 {
            sql: """ DROP TABLE IF EXISTS genepheno_pairs_sentences CASCADE;
            CREATE TABLE
            genepheno_pairs_sentences(doc_id text,
                         section_id text,
                         sent_id integer,
                         gene_mention_ids text,
                         gene_names text[],
                         gene_wordidxs text,
                         gene_is_corrects boolean[],
                         pheno_mention_ids text,
                         pheno_entities text[],
                         pheno_wordidxs text,
                         pheno_is_corrects boolean[])
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_25 {
            sql: """ DROP TABLE IF EXISTS hpo_abnormalities CASCADE;
            CREATE TABLE
            hpo_abnormalities(hpo_id text,
                 pheno_name text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_89 {
            sql: """ DROP TABLE IF EXISTS sentences_input_with_gene_mention CASCADE;
            CREATE TABLE
            sentences_input_with_gene_mention(doc_id text,
                                 section_id text,
                                 sent_id int,
                                 words text,
                                 lemmas text,
                                 poses text,
                                 ners text,
                                 dep_paths text,
                                 dep_parents text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_17 {
            sql: """ DROP TABLE IF EXISTS non_gene_acronyms CASCADE;
            CREATE TABLE
            non_gene_acronyms(id bigint,
                 doc_id text,
                 section_id text,
                 sent_id int,
                 short_wordidxs int[],
                 long_wordidxs int[],
                 mention_id text,
                 supertype text,
                 subtype text,
                 abbrev text,
                 definition text[],
                 is_correct boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_71 {
            sql: """ DROP TABLE IF EXISTS sentences_input_with_pheno_acronyms CASCADE;
            CREATE TABLE
            sentences_input_with_pheno_acronyms(doc_id text,
                                   section_id text,
                                   sent_id int,
                                   words text,
                                   lemmas text,
                                   poses text,
                                   ners text,
                                   dep_paths text,
                                   dep_parents text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_21 {
            sql: """ DROP TABLE IF EXISTS genepheno_holdout_set CASCADE;
            CREATE TABLE
            genepheno_holdout_set(doc_id text,
                     section_id text,
                     sent_id int,
                     gene_wordidxs int[],
                     pheno_wordidxs int[])
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_35 {
            sql: """ DROP TABLE IF EXISTS gene_mentions_filtered_inference CASCADE;
            CREATE TABLE
            gene_mentions_filtered_inference(relation_id text,
                                id bigint,
                                label boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_33 {
            sql: """ DROP TABLE IF EXISTS ensgene CASCADE;
            CREATE TABLE
            ensgene(bin int,
       name text,
       chrom text,
       strand text,
       txStart int,
       txEnd int,
       cdsStart int,
       cdsEnd int,
       exonCount int,
       exonStarts text,
       exonEnds text,
       score int,
       name2 text,
       cdsStartStat text,
       cdsEndStat text,
       exonFrames text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_39 {
            sql: """ DROP TABLE IF EXISTS non_gene_acronyms_inference CASCADE;
            CREATE TABLE
            non_gene_acronyms_inference(relation_id text,
                           id bigint,
                           label boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_8 {
            sql: """ DROP TABLE IF EXISTS pheno_features CASCADE;
            CREATE TABLE
            pheno_features(doc_id text,
              section_id text,
              mention_id text,
              feature text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_55 {
            sql: """ DROP TABLE IF EXISTS genepheno_pairs CASCADE;
            CREATE TABLE
            genepheno_pairs(doc_id text,
               section_id text,
               sent_id int,
               gene_mention_id text,
               gene_name text,
               gene_wordidxs text,
               gene_is_correct boolean,
               pheno_mention_id text,
               pheno_entity text,
               pheno_wordidxs text,
               pheno_is_correct boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_87 {
            sql: """ DROP TABLE IF EXISTS gene_mention_ids CASCADE;
            CREATE TABLE
            gene_mention_ids(doc_id text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_29 {
            sql: """ DROP TABLE IF EXISTS dummy CASCADE;
            CREATE TABLE
            dummy(a int,
     b int,
     c int)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_20 {
            sql: """ DROP TABLE IF EXISTS pheno_acronyms_features CASCADE;
            CREATE TABLE
            pheno_acronyms_features(doc_id text,
                       section_id text,
                       mention_id text,
                       feature text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_67 {
            sql: """ DROP TABLE IF EXISTS pheno_acronyms_aggregate CASCADE;
            CREATE TABLE
            pheno_acronyms_aggregate(doc_id text,
                        pa_section_ids text,
                        pa_sent_ids text,
                        pa_abbrevs text,
                        pheno_entities text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_12 {
            sql: """ DROP TABLE IF EXISTS genepheno_features CASCADE;
            CREATE TABLE
            genepheno_features(doc_id text,
                  section_id text,
                  relation_id text,
                  feature text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_4 {
            sql: """ DROP TABLE IF EXISTS gene_mentions CASCADE;
            CREATE TABLE
            gene_mentions(id bigint,
             doc_id text,
             section_id text,
             sent_id int,
             wordidxs int[],
             mention_id text,
             mapping_type text,
             supertype text,
             subtype text,
             gene_name text,
             words text[],
             is_correct boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_11 {
            sql: """ DROP TABLE IF EXISTS genepheno_causation CASCADE;
            CREATE TABLE
            genepheno_causation(id bigint,
                   relation_id text,
                   doc_id text,
                   section_id text,
                   sent_id int,
                   gene_mention_id text,
                   gene_name text,
                   gene_wordidxs int[],
                   pheno_mention_id text,
                   pheno_entity text,
                   pheno_wordidxs int[],
                   is_correct boolean,
                   supertype text,
                   subtype text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_10 {
            sql: """ DROP TABLE IF EXISTS genepheno_association CASCADE;
            CREATE TABLE
            genepheno_association(id bigint,
                     relation_id text,
                     doc_id text,
                     section_id text,
                     sent_id int,
                     gene_mention_id text,
                     gene_name text,
                     gene_wordidxs int[],
                     pheno_mention_id text,
                     pheno_entity text,
                     pheno_wordidxs int[],
                     is_correct boolean,
                     supertype text,
                     subtype text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_34 {
            sql: """ DROP TABLE IF EXISTS genepheno_relations CASCADE;
            CREATE TABLE
            genepheno_relations(id bigint,
                   relation_id text,
                   doc_id text,
                   section_id text,
                   sent_id int,
                   gene_mention_id text,
                   gene_entity text,
                   gene_wordidxs int[],
                   gene_is_correct boolean,
                   pheno_mention_id text,
                   pheno_entity text,
                   pheno_wordidxs int[],
                   pheno_is_correct boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_28 {
            sql: """ DROP TABLE IF EXISTS hgvs_hpo CASCADE;
            CREATE TABLE
            hgvs_hpo(variant text,
        hpo_id text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_22 {
            sql: """ DROP TABLE IF EXISTS genepheno_holdout_labels CASCADE;
            CREATE TABLE
            genepheno_holdout_labels(doc_id text,
                        section_id text,
                        sent_id int,
                        is_correct text,
                        type text,
                        labeler text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_1 {
            sql: """ DROP TABLE IF EXISTS sentences_input CASCADE;
            CREATE TABLE
            sentences_input(doc_id text,
               section_id text,
               sent_id int,
               words text,
               lemmas text,
               poses text,
               ners text,
               dep_paths text,
               dep_parents text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_91 {
            sql: """ DROP TABLE IF EXISTS variant_mentions_filtered CASCADE;
            CREATE TABLE
            variant_mentions_filtered(id bigint,
                         doc_id text,
                         section_id text,
                         sent_id int,
                         wordidxs int[],
                         mention_id text,
                         supertype text,
                         subtype text,
                         entity text,
                         variant_type text,
                         ivsNum text,
                         pos text,
                         posPlus text,
                         fromPos text,
                         toPos text,
                         seq text,
                         fromSeq text,
                         toSeq text,
                         words text[],
                         is_correct boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_15 {
            sql: """ DROP TABLE IF EXISTS test_nlp CASCADE;
            CREATE TABLE
            test_nlp(id bigint)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_5 {
            sql: """ DROP TABLE IF EXISTS variant_mentions CASCADE;
            CREATE TABLE
            variant_mentions(id bigint,
                doc_id text,
                section_id text,
                sent_id int,
                wordidxs int[],
                mention_id text,
                supertype text,
                subtype text,
                entity text,
                variant_type text,
                ivsNum text,
                pos text,
                posPlus text,
                fromPos text,
                toPos text,
                seq text,
                fromSeq text,
                toSeq text,
                words text[],
                is_correct boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_2 {
            sql: """ DROP TABLE IF EXISTS hpo_to_doc_via_mesh CASCADE;
            CREATE TABLE
            hpo_to_doc_via_mesh(hpo_id text,
                   doc_id text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_79 {
            sql: """ DROP TABLE IF EXISTS gene_to_transcripts CASCADE;
            CREATE TABLE
            gene_to_transcripts(gene_name text,
                   ensembl_ids text,
                   ensembl_transcripts text,
                   chroms text,
                   strands text,
                   txstarts text,
                   txends text,
                   exonstarts text,
                   exonends text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_13 {
            sql: """ DROP TABLE IF EXISTS genevariant_relations CASCADE;
            CREATE TABLE
            genevariant_relations(id bigint,
                     relation_id text,
                     doc_id text,
                     section1_id text,
                     sent1_id int,
                     section2_id text,
                     sent2_id int,
                     variant_mention_id text,
                     variant_entity text,
                     variant_wordidxs int[],
                     variant_is_correct boolean,
                     gene_mention_id text,
                     gene_name text,
                     gene_wordidxs int[],
                     gene_is_correct boolean,
                     is_correct boolean,
                     supertype text,
                     subtype text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_26 {
            sql: """ DROP TABLE IF EXISTS charite_canon CASCADE;
            CREATE TABLE
            charite_canon(hpo_id text,
             ensembl_id text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_69 {
            sql: """ DROP TABLE IF EXISTS pheno_acronyms_ids CASCADE;
            CREATE TABLE
            pheno_acronyms_ids(doc_id text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_27 {
            sql: """ DROP TABLE IF EXISTS charite CASCADE;
            CREATE TABLE
            charite(hpo_id text,
       ensembl_id text,
       source text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_16 {
            sql: """ DROP TABLE IF EXISTS plos_doi_to_pmid CASCADE;
            CREATE TABLE
            plos_doi_to_pmid(doi text,
                pmid text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_18 {
            sql: """ DROP TABLE IF EXISTS non_gene_acronyms_features CASCADE;
            CREATE TABLE
            non_gene_acronyms_features(doc_id text,
                          section_id text,
                          mention_id text,
                          feature text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_7 {
            sql: """ DROP TABLE IF EXISTS pheno_mentions CASCADE;
            CREATE TABLE
            pheno_mentions(id bigint,
              doc_id text,
              section_id text,
              sent_id int,
              wordidxs int[],
              mention_id text,
              supertype text,
              subtype text,
              entity text,
              words text[],
              is_correct boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_57 {
            sql: """ DROP TABLE IF EXISTS genevariant_pairs CASCADE;
            CREATE TABLE
            genevariant_pairs(doc_id text,
                 gene_section_id text,
                 gene_sent_id int,
                 variant_section_id text,
                 variant_sent_id int,
                 gene_mention_id text,
                 gene_name text,
                 gene_wordidxs text,
                 gene_is_correct boolean,
                 variant_mention_id text,
                 variant_entity text,
                 variant_wordidxs text,
                 variant_type text,
                 variant_ivsnum text,
                 variant_pos text,
                 variant_posplus text,
                 variant_frompos text,
                 variant_topos text,
                 variant_seq text,
                 variant_fromseq text,
                 variant_toseq text,
                 variant_is_correct boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_14 {
            sql: """ DROP TABLE IF EXISTS genevariant_features CASCADE;
            CREATE TABLE
            genevariant_features(doc_id text,
                    section_id text,
                    relation_id text,
                    feature text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_24 {
            sql: """ DROP TABLE IF EXISTS genepheno_association_canon CASCADE;
            CREATE TABLE
            genepheno_association_canon(hpo_id text,
                           ensembl_id text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_9 {
            sql: """ DROP TABLE IF EXISTS variant_features CASCADE;
            CREATE TABLE
            variant_features(doc_id text,
                section_id text,
                mention_id text,
                feature text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_36 {
            sql: """ DROP TABLE IF EXISTS pheno_mentions_filtered_inference CASCADE;
            CREATE TABLE
            pheno_mentions_filtered_inference(relation_id text,
                                 id bigint,
                                 label boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_32 {
            sql: """ DROP TABLE IF EXISTS ensembl_gene_sequences CASCADE;
            CREATE TABLE
            ensembl_gene_sequences(ensembl_transcript text,
                      n_seq text[])
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_38 {
            sql: """ DROP TABLE IF EXISTS genepheno_causation_inference CASCADE;
            CREATE TABLE
            genepheno_causation_inference(relation_id text,
                             id bigint,
                             label boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.extraction_rule_23 {
            sql: """ DROP TABLE IF EXISTS genepheno_causation_canon CASCADE;
            CREATE TABLE
            genepheno_causation_canon(hpo_id text,
                         ensembl_id text)
            """
            style: "sql_extractor"
          }

        deepdive.extraction.extractors.cleanup {
          sql: """
          TRUNCATE genevariant_coding_supervise_true;
          TRUNCATE gene_mentions_filtered;
          TRUNCATE sentences;
          TRUNCATE genevariant_relations_inference;
          TRUNCATE genes;
          TRUNCATE gene_features;
          TRUNCATE genepheno_association_inference;
          TRUNCATE pheno_acronyms;
          TRUNCATE ensembl_protein_sequences;
          TRUNCATE genepheno_pairs_sentences;
          TRUNCATE hpo_abnormalities;
          TRUNCATE sentences_input_with_gene_mention;
          TRUNCATE non_gene_acronyms;
          TRUNCATE sentences_input_with_pheno_acronyms;
          TRUNCATE genepheno_holdout_set;
          TRUNCATE gene_mentions_filtered_inference;
          TRUNCATE ensgene;
          TRUNCATE non_gene_acronyms_inference;
          TRUNCATE pheno_features;
          TRUNCATE genepheno_pairs;
          TRUNCATE gene_mention_ids;
          TRUNCATE dummy;
          TRUNCATE pheno_acronyms_features;
          TRUNCATE pheno_acronyms_aggregate;
          TRUNCATE genepheno_features;
          TRUNCATE gene_mentions;
          TRUNCATE genepheno_causation;
          TRUNCATE genepheno_association;
          TRUNCATE genepheno_relations;
          TRUNCATE hgvs_hpo;
          TRUNCATE genepheno_holdout_labels;
          TRUNCATE sentences_input;
          TRUNCATE variant_mentions_filtered;
          TRUNCATE test_nlp;
          TRUNCATE variant_mentions;
          TRUNCATE hpo_to_doc_via_mesh;
          TRUNCATE gene_to_transcripts;
          TRUNCATE genevariant_relations;
          TRUNCATE charite_canon;
          TRUNCATE pheno_acronyms_ids;
          TRUNCATE charite;
          TRUNCATE plos_doi_to_pmid;
          TRUNCATE non_gene_acronyms_features;
          TRUNCATE pheno_mentions;
          TRUNCATE genevariant_pairs;
          TRUNCATE genevariant_features;
          TRUNCATE genepheno_association_canon;
          TRUNCATE variant_features;
          TRUNCATE pheno_mentions_filtered_inference;
          TRUNCATE ensembl_gene_sequences;
          TRUNCATE genepheno_causation_inference;
          TRUNCATE genepheno_causation_canon;
          """
          style: "sql_extractor"
        }

      deepdive.extraction.extractors.extraction_rule_84 {
        sql: """ 
        INSERT INTO genevariant_coding_supervise_true SELECT DISTINCT R0.doc_id AS "variant_mentions.R0.doc_id", R0.mention_id AS "variant_mentions.R0.mention_id", R0.entity AS "variant_mentions.R0.entity", R0.pos AS "variant_mentions.R0.pos", R0.fromSeq AS "variant_mentions.R0.fromSeq", R0.toSeq AS "variant_mentions.R0.toSeq", ARRAY_AGG(R1.gene_name) AS column_6
FROM variant_mentions R0, gene_mentions R1, genes R2, ensgene R3, ensembl_gene_sequences R4
        WHERE R1.doc_id = R0.doc_id  AND R2.gene_name = R1.gene_name  AND R3.name2 = R2.ensembl_id  AND R4.ensembl_transcript = R3.name 
        GROUP BY R0.doc_id, R0.mention_id, R0.entity, R0.pos, R0.fromSeq, R0.toSeq
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_48" ,  "extraction_rule_44" ]
      }
    

      deepdive.extraction.extractors.extraction_rule_86 {
        sql: """ 
        INSERT INTO gene_mentions_filtered SELECT DISTINCT R0.id AS "gene_mentions.R0.id", R0.doc_id AS "gene_mentions.R0.doc_id", R0.section_id AS "gene_mentions.R0.section_id", R0.sent_id AS "gene_mentions.R0.sent_id", array_to_string(R0.wordidxs, '|^|') AS column_4, R0.mention_id AS "gene_mentions.R0.mention_id", R0.mapping_type AS "gene_mentions.R0.mapping_type", R0.supertype AS "gene_mentions.R0.supertype", R0.subtype AS "gene_mentions.R0.subtype", R0.gene_name AS "gene_mentions.R0.gene_name", array_to_string(R0.words, '|^|') AS column_10, R0.is_correct AS "gene_mentions.R0.is_correct"
FROM gene_mentions R0, genepheno_relations R1
        
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_44" ,  "extraction_rule_78" ]
      }
    

      deepdive.extraction.extractors.extraction_rule_90 {
        sql: """ 
        INSERT INTO sentences_input_with_gene_mention SELECT R0.doc_id AS "sentences_input.R0.doc_id", R0.section_id AS "sentences_input.R0.section_id", R0.sent_id AS "sentences_input.R0.sent_id", R0.words AS "sentences_input.R0.words", R0.lemmas AS "sentences_input.R0.lemmas", R0.poses AS "sentences_input.R0.poses", R0.ners AS "sentences_input.R0.ners", R0.dep_paths AS "sentences_input.R0.dep_paths", R0.dep_parents AS "sentences_input.R0.dep_parents"
FROM sentences_input R0, gene_mention_ids R1
        WHERE R1.doc_id = R0.doc_id 
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_41" ,  "extraction_rule_88" ]
      }
    

      deepdive.extraction.extractors.extraction_rule_72 {
        sql: """ 
        INSERT INTO sentences_input_with_pheno_acronyms SELECT R0.doc_id AS "sentences_input.R0.doc_id", R0.section_id AS "sentences_input.R0.section_id", R0.sent_id AS "sentences_input.R0.sent_id", R0.words AS "sentences_input.R0.words", R0.lemmas AS "sentences_input.R0.lemmas", R0.poses AS "sentences_input.R0.poses", R0.ners AS "sentences_input.R0.ners", R0.dep_paths AS "sentences_input.R0.dep_paths", R0.dep_parents AS "sentences_input.R0.dep_parents"
FROM sentences_input R0, pheno_acronyms_ids R1
        WHERE R1.doc_id = R0.doc_id 
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_41" ,  "extraction_rule_70" ]
      }
    

      deepdive.extraction.extractors.extraction_rule_56 {
        sql: """ 
        INSERT INTO genepheno_pairs SELECT R0.doc_id AS "gene_mentions.R0.doc_id", R0.section_id AS "gene_mentions.R0.section_id", R0.sent_id AS "gene_mentions.R0.sent_id", R0.mention_id AS "gene_mentions.R0.mention_id", R0.gene_name AS "gene_mentions.R0.gene_name", ARRAY_TO_STRING(R0.wordidxs, '|~|') AS column_5, R0.is_correct AS "gene_mentions.R0.is_correct", R1.mention_id AS "pheno_mentions.R1.mention_id", R1.entity AS "pheno_mentions.R1.entity", ARRAY_TO_STRING(R1.wordidxs, '|~|') AS column_9, R1.is_correct AS "pheno_mentions.R1.is_correct"
FROM gene_mentions R0, pheno_mentions R1
        WHERE R1.doc_id = R0.doc_id  AND R1.section_id = R0.section_id  AND R1.sent_id = R0.sent_id 
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_44" ,  "extraction_rule_50" ,  "extraction_rule_74" ]
      }
    

      deepdive.extraction.extractors.extraction_rule_88 {
        sql: """ 
        INSERT INTO gene_mention_ids SELECT DISTINCT R0.doc_id AS "gene_mentions_filtered.R0.doc_id"
FROM gene_mentions_filtered R0
        
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_86" ]
      }
    

      deepdive.extraction.extractors.extraction_rule_65 {
        sql: """ DROP VIEW IF EXISTS pheno_acronyms_extract_candidates_view_temp_2;
        CREATE VIEW pheno_acronyms_extract_candidates_view_temp_2 AS SELECT R0.doc_id AS column_0, R0.section_id AS column_1, R0.sent_id AS column_2, R0.words AS column_3, string_to_array(R0.words, '|^|') AS column_4, R0.dep_paths AS column_5, R0.dep_parents AS column_6, R0.lemmas AS column_7, R0.poses AS column_8, R0.ners AS column_9, R1.column_3 AS column_10, R1.column_4 AS column_11
FROM sentences_input R0, pheno_acronyms_extract_candidates_view_temp_1 R1
        WHERE R1.column_0 = R0.doc_id  AND R1.column_1 = R0.section_id  AND R1.column_2 = R0.sent_id  AND R0.words LIKE '%-LRB-%'
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_41" ,  "extraction_rule_64" ]
      }
    

      deepdive.extraction.extractors.extraction_rule_68 {
        sql: """ 
        INSERT INTO pheno_acronyms_aggregate SELECT DISTINCT R0.doc_id AS "pheno_acronyms.R0.doc_id", array_to_string(ARRAY_AGG(R0.section_id), '|^|') AS column_1, array_to_string(ARRAY_AGG(R0.sent_id), '|^|') AS column_2, array_to_string(ARRAY_AGG(R0.abbrev), '|^|') AS column_3, array_to_string(ARRAY_AGG(R0.entity), '|^|') AS column_4
FROM pheno_acronyms R0
        WHERE R0.is_correct = 't'
        GROUP BY R0.doc_id
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_66" ]
      }
    

      deepdive.extraction.extractors.extraction_rule_41 {
        sql: """ 
        INSERT INTO sentences_input SELECT R0.doc_id AS "sentences.R0.doc_id", R0.section_id AS "sentences.R0.section_id", R0.sent_id AS "sentences.R0.sent_id", ARRAY_TO_STRING(R0.words, '|^|') AS column_3, ARRAY_TO_STRING(R0.lemmas, '|^|') AS column_4, ARRAY_TO_STRING(R0.poses, '|^|') AS column_5, ARRAY_TO_STRING(R0.ners, '|^|') AS column_6, ARRAY_TO_STRING(R0.dep_paths, '|^|') AS column_7, ARRAY_TO_STRING(R0.dep_parents, '|^|') AS column_8
FROM sentences R0
        
        """
        style: "sql_extractor"
          
      }
    

      deepdive.extraction.extractors.extraction_rule_51 {
        sql: """ 
        INSERT INTO variant_mentions_filtered SELECT R0.id AS "variant_mentions.R0.id", R0.doc_id AS "variant_mentions.R0.doc_id", R0.section_id AS "variant_mentions.R0.section_id", R0.sent_id AS "variant_mentions.R0.sent_id", R0.wordidxs AS "variant_mentions.R0.wordidxs", R0.mention_id AS "variant_mentions.R0.mention_id", R0.supertype AS "variant_mentions.R0.supertype", R0.subtype AS "variant_mentions.R0.subtype", R0.entity AS "variant_mentions.R0.entity", R0.variant_type AS "variant_mentions.R0.variant_type", R0.ivsNum AS "variant_mentions.R0.ivsNum", R0.pos AS "variant_mentions.R0.pos", R0.posPlus AS "variant_mentions.R0.posPlus", R0.fromPos AS "variant_mentions.R0.fromPos", R0.toPos AS "variant_mentions.R0.toPos", R0.seq AS "variant_mentions.R0.seq", R0.fromSeq AS "variant_mentions.R0.fromSeq", R0.toSeq AS "variant_mentions.R0.toSeq", R0.words AS "variant_mentions.R0.words", R0.is_correct AS "variant_mentions.R0.is_correct"
FROM variant_mentions R0
        
UNION ALL
SELECT DISTINCT R0.id AS "variant_mentions.R0.id", R0.doc_id AS "variant_mentions.R0.doc_id", R0.section_id AS "variant_mentions.R0.section_id", R0.sent_id AS "variant_mentions.R0.sent_id", R0.wordidxs AS "variant_mentions.R0.wordidxs", R0.mention_id AS "variant_mentions.R0.mention_id", R0.supertype AS "variant_mentions.R0.supertype", R0.subtype AS "variant_mentions.R0.subtype", R0.entity AS "variant_mentions.R0.entity", R0.variant_type AS "variant_mentions.R0.variant_type", R0.ivsNum AS "variant_mentions.R0.ivsNum", R0.pos AS "variant_mentions.R0.pos", R0.posPlus AS "variant_mentions.R0.posPlus", R0.fromPos AS "variant_mentions.R0.fromPos", R0.toPos AS "variant_mentions.R0.toPos", R0.seq AS "variant_mentions.R0.seq", R0.fromSeq AS "variant_mentions.R0.fromSeq", R0.toSeq AS "variant_mentions.R0.toSeq", R0.words AS "variant_mentions.R0.words", R0.is_correct AS "variant_mentions.R0.is_correct"
FROM variant_mentions R0
        
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_48" ]
      }
    

      deepdive.extraction.extractors.extraction_rule_80 {
        sql: """ 
        INSERT INTO gene_to_transcripts SELECT DISTINCT R0.gene_name AS "genes.R0.gene_name", array_to_string(ARRAY_AGG(R0.ensembl_id), '|~|') AS column_1, array_to_string(ARRAY_AGG(R1.name), '|~|') AS column_2, array_to_string(ARRAY_AGG(R1.chrom), '|~|') AS column_3, array_to_string(ARRAY_AGG(R1.strand), '|~|') AS column_4, array_to_string(ARRAY_AGG(R1.cdsStart), '|~|') AS column_5, array_to_string(ARRAY_AGG(R1.cdsEnd), '|~|') AS column_6, array_to_string(ARRAY_AGG(R1.exonStarts), '|~|') AS column_7, array_to_string(ARRAY_AGG(R1.exonEnds), '|~|') AS column_8
FROM genes R0, ensgene R1
        WHERE R1.name2 = R0.ensembl_id 
        GROUP BY R0.gene_name
        """
        style: "sql_extractor"
          
      }
    

      deepdive.extraction.extractors.extraction_rule_70 {
        sql: """ 
        INSERT INTO pheno_acronyms_ids SELECT DISTINCT R0.doc_id AS "pheno_acronyms_aggregate.R0.doc_id"
FROM pheno_acronyms_aggregate R0
        
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_68" ]
      }
    

      deepdive.extraction.extractors.extraction_rule_64 {
        sql: """ DROP VIEW IF EXISTS pheno_acronyms_extract_candidates_view_temp_1;
        CREATE VIEW pheno_acronyms_extract_candidates_view_temp_1 AS SELECT DISTINCT R0.doc_id AS column_0, R0.section_id AS column_1, R0.sent_id AS column_2, R0.wordidxs AS column_3, R0.entity AS column_4
FROM pheno_mentions R0
        WHERE (R0.is_correct = 't' OR R0.is_correct IS NULL)
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_50" ,  "extraction_rule_74" ]
      }
    

      deepdive.extraction.extractors.extraction_rule_60 {
        sql: """ DROP VIEW IF EXISTS non_gene_acronyms_extract_candidates_view_temp_1;
        CREATE VIEW non_gene_acronyms_extract_candidates_view_temp_1 AS SELECT DISTINCT R0.doc_id AS column_0, R0.section_id AS column_1, R0.sent_id AS column_2, R0.wordidxs AS column_3
FROM gene_mentions R0
        
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_44" ]
      }
    

      deepdive.extraction.extractors.extraction_rule_58 {
        sql: """ 
        INSERT INTO genevariant_pairs SELECT R0.doc_id AS "gene_mentions.R0.doc_id", R0.section_id AS "gene_mentions.R0.section_id", R0.sent_id AS "gene_mentions.R0.sent_id", R1.section_id AS "variant_mentions.R1.section_id", R1.sent_id AS "variant_mentions.R1.sent_id", R0.mention_id AS "gene_mentions.R0.mention_id", R0.gene_name AS "gene_mentions.R0.gene_name", array_to_string(R0.wordidxs, '|^|') AS column_7, R0.is_correct AS "gene_mentions.R0.is_correct", R1.mention_id AS "variant_mentions.R1.mention_id", R1.entity AS "variant_mentions.R1.entity", array_to_string(R1.wordidxs, '|^|') AS column_11, R1.variant_type AS "variant_mentions.R1.variant_type", R1.ivsNum AS "variant_mentions.R1.ivsNum", R1.pos AS "variant_mentions.R1.pos", R1.posPlus AS "variant_mentions.R1.posPlus", R1.fromPos AS "variant_mentions.R1.fromPos", R1.toPos AS "variant_mentions.R1.toPos", R1.seq AS "variant_mentions.R1.seq", R1.fromSeq AS "variant_mentions.R1.fromSeq", R1.toSeq AS "variant_mentions.R1.toSeq", R1.is_correct AS "variant_mentions.R1.is_correct"
FROM gene_mentions R0, variant_mentions R1
        WHERE R1.doc_id = R0.doc_id 
        """
        style: "sql_extractor"
          dependencies: [ "extraction_rule_44" ,  "extraction_rule_48" ]
      }
    

        deepdive.extraction.extractors.extraction_rule_44 {
          input: """ SELECT R0.doc_id AS "sentences_input.R0.doc_id", R0.section_id AS "sentences_input.R0.section_id", R0.sent_id AS "sentences_input.R0.sent_id", R0.words AS "sentences_input.R0.words", R0.dep_paths AS "sentences_input.R0.dep_paths", R0.dep_parents AS "sentences_input.R0.dep_parents", R0.lemmas AS "sentences_input.R0.lemmas", R0.poses AS "sentences_input.R0.poses", R0.ners AS "sentences_input.R0.ners"
FROM sentences_input R0
        
          """
          output_relation: "gene_mentions"
          udf: ${APP_HOME}"/code/gene_extract_candidates.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_41" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_46 {
          input: """ SELECT R0.doc_id AS "sentences_input.R0.doc_id", R0.section_id AS "sentences_input.R0.section_id", R0.sent_id AS "sentences_input.R0.sent_id", R0.words AS "sentences_input.R0.words", R0.lemmas AS "sentences_input.R0.lemmas", R0.poses AS "sentences_input.R0.poses", R0.ners AS "sentences_input.R0.ners", R0.dep_paths AS "sentences_input.R0.dep_paths", R0.dep_parents AS "sentences_input.R0.dep_parents", R1.mention_id AS "gene_mentions.R1.mention_id", R1.mapping_type AS "gene_mentions.R1.mapping_type", ARRAY_TO_STRING(R1.wordidxs, '|^|') AS column_11
FROM sentences_input R0, gene_mentions R1
        WHERE R1.doc_id = R0.doc_id  AND R1.section_id = R0.section_id  AND R1.sent_id = R0.sent_id 
          """
          output_relation: "gene_features"
          udf: ${APP_HOME}"/code/gene_extract_features.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_41" ,  "extraction_rule_44" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_48 {
          input: """ SELECT R0.doc_id AS "sentences_input.R0.doc_id", R0.section_id AS "sentences_input.R0.section_id", R0.sent_id AS "sentences_input.R0.sent_id", R0.words AS "sentences_input.R0.words"
FROM sentences_input R0
        
          """
          output_relation: "variant_mentions"
          udf: ${APP_HOME}"/code/variant_extract_candidates.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_41" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_50 {
          input: """ SELECT R0.doc_id AS "sentences_input.R0.doc_id", R0.section_id AS "sentences_input.R0.section_id", R0.sent_id AS "sentences_input.R0.sent_id", R0.words AS "sentences_input.R0.words", R0.lemmas AS "sentences_input.R0.lemmas", R0.poses AS "sentences_input.R0.poses", R0.ners AS "sentences_input.R0.ners"
FROM sentences_input R0
        
          """
          output_relation: "pheno_mentions"
          udf: ${APP_HOME}"/code/pheno_extract_candidates.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_41" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_53 {
          input: """ SELECT R0.doc_id AS "sentences_input.R0.doc_id", R0.section_id AS "sentences_input.R0.section_id", R0.sent_id AS "sentences_input.R0.sent_id", R0.words AS "sentences_input.R0.words", R0.lemmas AS "sentences_input.R0.lemmas", R0.poses AS "sentences_input.R0.poses", R0.ners AS "sentences_input.R0.ners", R0.dep_paths AS "sentences_input.R0.dep_paths", R0.dep_parents AS "sentences_input.R0.dep_parents", R1.mention_id AS "variant_mentions_filtered.R1.mention_id", array_to_string(R1.wordidxs, '|^|') AS column_10
FROM sentences_input R0, variant_mentions_filtered R1
        WHERE R1.doc_id = R0.doc_id  AND R1.section_id = R0.section_id  AND R1.sent_id = R0.sent_id 
          """
          output_relation: "variant_features"
          udf: ${APP_HOME}"/code/variant_extract_features.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_41" ,  "extraction_rule_51" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_62 {
          input: """ SELECT R0.doc_id AS "sentences_input.R0.doc_id", R0.section_id AS "sentences_input.R0.section_id", R0.sent_id AS "sentences_input.R0.sent_id", R0.words AS "sentences_input.R0.words", R0.lemmas AS "sentences_input.R0.lemmas", R0.poses AS "sentences_input.R0.poses", R0.ners AS "sentences_input.R0.ners", R0.dep_paths AS "sentences_input.R0.dep_paths", R0.dep_parents AS "sentences_input.R0.dep_parents", R1.mention_id AS "non_gene_acronyms.R1.mention_id", R1.supertype AS "non_gene_acronyms.R1.supertype", array_to_string(R1.short_wordidxs, '|^|') AS column_11, array_to_string(R1.long_wordidxs, '|^|') AS column_12
FROM sentences_input R0, non_gene_acronyms R1
        WHERE R1.doc_id = R0.doc_id  AND R1.section_id = R0.section_id  AND R1.sent_id = R0.sent_id 
          """
          output_relation: "non_gene_acronyms_features"
          udf: ${APP_HOME}"/code/non_gene_acronyms_extract_features.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_41" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_66 {
          input: """ SELECT R0.column_0 AS "pheno_acronyms_extract_candidates_view_temp_2.R0.column_0", R0.column_1 AS "pheno_acronyms_extract_candidates_view_temp_2.R0.column_1", R0.column_2 AS "pheno_acronyms_extract_candidates_view_temp_2.R0.column_2", R0.column_3 AS "pheno_acronyms_extract_candidates_view_temp_2.R0.column_3", R0.column_5 AS "pheno_acronyms_extract_candidates_view_temp_2.R0.column_5", R0.column_6 AS "pheno_acronyms_extract_candidates_view_temp_2.R0.column_6", R0.column_7 AS "pheno_acronyms_extract_candidates_view_temp_2.R0.column_7", R0.column_8 AS "pheno_acronyms_extract_candidates_view_temp_2.R0.column_8", R0.column_9 AS "pheno_acronyms_extract_candidates_view_temp_2.R0.column_9", R0.column_10 AS "pheno_acronyms_extract_candidates_view_temp_2.R0.column_10", R0.column_11 AS "pheno_acronyms_extract_candidates_view_temp_2.R0.column_11"
FROM pheno_acronyms_extract_candidates_view_temp_2 R0
        
          """
          output_relation: "pheno_acronyms"
          udf: ${APP_HOME}"/code/pheno_acronyms_extract_candidates.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_65" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_74 {
          input: """ SELECT R0.doc_id AS "sentences_input_with_pheno_acronyms.R0.doc_id", R0.section_id AS "sentences_input_with_pheno_acronyms.R0.section_id", R0.sent_id AS "sentences_input_with_pheno_acronyms.R0.sent_id", R0.words AS "sentences_input_with_pheno_acronyms.R0.words", R0.lemmas AS "sentences_input_with_pheno_acronyms.R0.lemmas", R0.poses AS "sentences_input_with_pheno_acronyms.R0.poses", R0.ners AS "sentences_input_with_pheno_acronyms.R0.ners", R1.pa_abbrevs AS "pheno_acronyms_aggregate.R1.pa_abbrevs", R1.pheno_entities AS "pheno_acronyms_aggregate.R1.pheno_entities", R1.pa_section_ids AS "pheno_acronyms_aggregate.R1.pa_section_ids", R1.pa_sent_ids AS "pheno_acronyms_aggregate.R1.pa_sent_ids"
FROM sentences_input_with_pheno_acronyms R0, pheno_acronyms_aggregate R1
        WHERE R1.doc_id = R0.doc_id 
          """
          output_relation: "pheno_mentions"
          udf: ${APP_HOME}"/code/pheno_acronyms_to_mentions.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_72" ,  "extraction_rule_68" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_76 {
          input: """ SELECT R0.doc_id AS "sentences_input.R0.doc_id", R0.section_id AS "sentences_input.R0.section_id", R0.sent_id AS "sentences_input.R0.sent_id", R0.words AS "sentences_input.R0.words", R0.lemmas AS "sentences_input.R0.lemmas", R0.poses AS "sentences_input.R0.poses", R0.ners AS "sentences_input.R0.ners", R0.dep_paths AS "sentences_input.R0.dep_paths", R0.dep_parents AS "sentences_input.R0.dep_parents", R1.mention_id AS "pheno_acronyms.R1.mention_id", R1.supertype AS "pheno_acronyms.R1.supertype", array_to_string(R1.short_wordidxs, '|^|') AS column_11, array_to_string(R1.long_wordidxs, '|^|') AS column_12
FROM sentences_input R0, pheno_acronyms R1
        WHERE R1.doc_id = R0.doc_id  AND R1.section_id = R0.section_id  AND R1.sent_id = R0.sent_id 
          """
          output_relation: "pheno_acronyms_features"
          udf: ${APP_HOME}"/code/pheno_acronyms_extract_features.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_41" ,  "extraction_rule_66" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_78 {
          input: """ SELECT R0.doc_id AS "sentences_input.R0.doc_id", R0.section_id AS "sentences_input.R0.section_id", R0.sent_id AS "sentences_input.R0.sent_id", R0.words AS "sentences_input.R0.words", R0.lemmas AS "sentences_input.R0.lemmas", R0.poses AS "sentences_input.R0.poses", R0.dep_paths AS "sentences_input.R0.dep_paths", R0.dep_parents AS "sentences_input.R0.dep_parents", R1.gene_mention_ids AS "genepheno_pairs_sentences.R1.gene_mention_ids", R1.gene_names AS "genepheno_pairs_sentences.R1.gene_names", R1.gene_wordidxs AS "genepheno_pairs_sentences.R1.gene_wordidxs", R1.gene_is_corrects AS "genepheno_pairs_sentences.R1.gene_is_corrects", R1.pheno_mention_ids AS "genepheno_pairs_sentences.R1.pheno_mention_ids", R1.pheno_entities AS "genepheno_pairs_sentences.R1.pheno_entities", R1.pheno_wordidxs AS "genepheno_pairs_sentences.R1.pheno_wordidxs", R1.pheno_is_corrects AS "genepheno_pairs_sentences.R1.pheno_is_corrects"
FROM sentences_input R0, genepheno_pairs_sentences R1
        WHERE R1.doc_id = R0.doc_id  AND R1.section_id = R0.section_id  AND R1.sent_id = R0.sent_id 
          """
          output_relation: "genepheno_relations"
          udf: ${APP_HOME}"/code/genepheno_extract_candidates.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_41" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_82 {
          input: """ SELECT R0.doc_id AS "genevariant_pairs.R0.doc_id", R0.variant_section_id AS "genevariant_pairs.R0.variant_section_id", R0.variant_sent_id AS "genevariant_pairs.R0.variant_sent_id", R0.variant_entity AS "genevariant_pairs.R0.variant_entity", R0.variant_wordidxs AS "genevariant_pairs.R0.variant_wordidxs", R0.variant_type AS "genevariant_pairs.R0.variant_type", R0.variant_ivsnum AS "genevariant_pairs.R0.variant_ivsnum", R0.variant_pos AS "genevariant_pairs.R0.variant_pos", R0.variant_posplus AS "genevariant_pairs.R0.variant_posplus", R0.variant_frompos AS "genevariant_pairs.R0.variant_frompos", R0.variant_topos AS "genevariant_pairs.R0.variant_topos", R0.variant_seq AS "genevariant_pairs.R0.variant_seq", R0.variant_fromseq AS "genevariant_pairs.R0.variant_fromseq", R0.variant_toseq AS "genevariant_pairs.R0.variant_toseq", R0.variant_is_correct AS "genevariant_pairs.R0.variant_is_correct", array_to_string(ARRAY_AGG(R0.gene_section_id), '|^|') AS column_15, array_to_string(ARRAY_AGG(R0.gene_sent_id), '|^|') AS column_16, array_to_string(ARRAY_AGG(R0.gene_wordidxs), '|^|') AS column_17, array_to_string(ARRAY_AGG(R0.gene_name), '|^|') AS column_18, array_to_string(ARRAY_AGG(R0.gene_is_correct), '|^|') AS column_19, array_to_string(ARRAY_AGG(R1.ensembl_ids), '|^|') AS column_20, array_to_string(ARRAY_AGG(R1.ensembl_transcripts), '|^|') AS column_21, array_to_string(ARRAY_AGG(R1.chroms), '|^|') AS column_22, array_to_string(ARRAY_AGG(R1.strands), '|^|') AS column_23, array_to_string(ARRAY_AGG(R1.txstarts), '|^|') AS column_24, array_to_string(ARRAY_AGG(R1.txends), '|^|') AS column_25, array_to_string(ARRAY_AGG(R1.exonstarts), '|^|') AS column_26, array_to_string(ARRAY_AGG(R1.exonends), '|^|') AS column_27
FROM genevariant_pairs R0, gene_to_transcripts R1
        WHERE R1.gene_name = R0.gene_name 
        GROUP BY R0.doc_id, R0.variant_section_id, R0.variant_sent_id, R0.variant_entity, R0.variant_wordidxs, R0.variant_type, R0.variant_ivsnum, R0.variant_pos, R0.variant_posplus, R0.variant_frompos, R0.variant_topos, R0.variant_seq, R0.variant_fromseq, R0.variant_toseq, R0.variant_is_correct
          """
          output_relation: "genevariant_relations"
          udf: ${APP_HOME}"/code/genevariant_extract_candidates.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_58" ,  "extraction_rule_80" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_94 {
          input: """ SELECT R0.relation_id AS "genepheno_relations.R0.relation_id", R0.doc_id AS "genepheno_relations.R0.doc_id", R0.section_id AS "genepheno_relations.R0.section_id", R0.sent_id AS "genepheno_relations.R0.sent_id", R0.gene_mention_id AS "genepheno_relations.R0.gene_mention_id", R0.gene_wordidxs AS "genepheno_relations.R0.gene_wordidxs", R0.pheno_mention_id AS "genepheno_relations.R0.pheno_mention_id", R0.pheno_wordidxs AS "genepheno_relations.R0.pheno_wordidxs", R1.words AS "sentences_input.R1.words", R1.lemmas AS "sentences_input.R1.lemmas", R1.poses AS "sentences_input.R1.poses", R1.ners AS "sentences_input.R1.ners", R1.dep_paths AS "sentences_input.R1.dep_paths", R1.dep_parents AS "sentences_input.R1.dep_parents"
FROM genepheno_relations R0, sentences_input R1
        WHERE R1.doc_id = R0.doc_id  AND R1.section_id = R0.section_id  AND R1.sent_id = R0.sent_id 
          """
          output_relation: "genepheno_features"
          udf: ${APP_HOME}"/code/genepheno_extract_features.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_78" ,  "extraction_rule_41" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_96 {
          input: """ SELECT R0.relation_id AS "genepheno_relations.R0.relation_id", R0.doc_id AS "genepheno_relations.R0.doc_id", R0.section_id AS "genepheno_relations.R0.section_id", R0.sent_id AS "genepheno_relations.R0.sent_id", R0.gene_mention_id AS "genepheno_relations.R0.gene_mention_id", R0.gene_entity AS "genepheno_relations.R0.gene_entity", R0.gene_wordidxs AS "genepheno_relations.R0.gene_wordidxs", R0.gene_is_correct AS "genepheno_relations.R0.gene_is_correct", R0.pheno_mention_id AS "genepheno_relations.R0.pheno_mention_id", R0.pheno_entity AS "genepheno_relations.R0.pheno_entity", R0.pheno_wordidxs AS "genepheno_relations.R0.pheno_wordidxs", R0.pheno_is_correct AS "genepheno_relations.R0.pheno_is_correct", R1.words AS "sentences_input.R1.words", R1.lemmas AS "sentences_input.R1.lemmas", R1.poses AS "sentences_input.R1.poses", R1.dep_paths AS "sentences_input.R1.dep_paths", R1.dep_parents AS "sentences_input.R1.dep_parents"
FROM genepheno_relations R0, sentences_input R1
        WHERE R1.doc_id = R0.doc_id  AND R1.section_id = R0.section_id  AND R1.sent_id = R0.sent_id 
          """
          output_relation: "genepheno_association"
          udf: ${APP_HOME}"/code/genepheno_association_supervision.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_78" ,  "extraction_rule_41" ]
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.extraction_rule_98 {
          input: """ SELECT R0.relation_id AS "genepheno_relations.R0.relation_id", R0.doc_id AS "genepheno_relations.R0.doc_id", R0.section_id AS "genepheno_relations.R0.section_id", R0.sent_id AS "genepheno_relations.R0.sent_id", R0.gene_mention_id AS "genepheno_relations.R0.gene_mention_id", R0.gene_entity AS "genepheno_relations.R0.gene_entity", R0.gene_wordidxs AS "genepheno_relations.R0.gene_wordidxs", R0.gene_is_correct AS "genepheno_relations.R0.gene_is_correct", R0.pheno_mention_id AS "genepheno_relations.R0.pheno_mention_id", R0.pheno_entity AS "genepheno_relations.R0.pheno_entity", R0.pheno_wordidxs AS "genepheno_relations.R0.pheno_wordidxs", R0.pheno_is_correct AS "genepheno_relations.R0.pheno_is_correct", R1.words AS "sentences_input.R1.words", R1.lemmas AS "sentences_input.R1.lemmas", R1.poses AS "sentences_input.R1.poses", R1.dep_paths AS "sentences_input.R1.dep_paths", R1.dep_parents AS "sentences_input.R1.dep_parents"
FROM genepheno_relations R0, sentences_input R1
        WHERE R1.doc_id = R0.doc_id  AND R1.section_id = R0.section_id  AND R1.sent_id = R0.sent_id 
          """
          output_relation: "genepheno_causation"
          udf: ${APP_HOME}"/code/genepheno_causation_supervision.py"
          style: "tsv_extractor" 
          dependencies: [ "extraction_rule_78" ,  "extraction_rule_41" ]
          parallelism: ${PARALLELISM}
        }
      
deepdive.pipeline.run: ${PIPELINE}
deepdive.pipeline.pipelines.initdb: [extraction_rule_83, extraction_rule_85, extraction_rule_0, extraction_rule_40, extraction_rule_3, extraction_rule_6, extraction_rule_37, extraction_rule_19, extraction_rule_31, extraction_rule_30, extraction_rule_25, extraction_rule_89, extraction_rule_17, extraction_rule_71, extraction_rule_21, extraction_rule_35, extraction_rule_33, extraction_rule_39, extraction_rule_8, extraction_rule_55, extraction_rule_87, extraction_rule_29, extraction_rule_20, extraction_rule_67, extraction_rule_12, extraction_rule_4, extraction_rule_11, extraction_rule_10, extraction_rule_34, extraction_rule_28, extraction_rule_22, extraction_rule_1, extraction_rule_91, extraction_rule_15, extraction_rule_5, extraction_rule_2, extraction_rule_79, extraction_rule_13, extraction_rule_26, extraction_rule_69, extraction_rule_27, extraction_rule_16, extraction_rule_18, extraction_rule_7, extraction_rule_57, extraction_rule_14, extraction_rule_24, extraction_rule_9, extraction_rule_36, extraction_rule_32, extraction_rule_38, extraction_rule_23]
deepdive.pipeline.pipelines.extraction: [extraction_rule_90, extraction_rule_58, extraction_rule_65, extraction_rule_53, extraction_rule_72, extraction_rule_88, extraction_rule_50, extraction_rule_66, extraction_rule_80, extraction_rule_48, extraction_rule_94, extraction_rule_44, extraction_rule_76, extraction_rule_98, extraction_rule_84, extraction_rule_60, extraction_rule_56, extraction_rule_86, extraction_rule_41, extraction_rule_96, extraction_rule_74, extraction_rule_46, extraction_rule_68, extraction_rule_70, extraction_rule_64, extraction_rule_51, extraction_rule_78, extraction_rule_62, extraction_rule_82]
deepdive.pipeline.pipelines.endtoend: [extraction_rule_90, extraction_rule_58, extraction_rule_65, extraction_rule_53, extraction_rule_72, extraction_rule_88, extraction_rule_50, extraction_rule_66, extraction_rule_80, extraction_rule_48, extraction_rule_94, extraction_rule_44, extraction_rule_76, extraction_rule_98, extraction_rule_84, extraction_rule_60, extraction_rule_56, extraction_rule_86, extraction_rule_41, extraction_rule_96, extraction_rule_74, extraction_rule_46, extraction_rule_68, extraction_rule_70, extraction_rule_64, extraction_rule_51, extraction_rule_78, extraction_rule_62, extraction_rule_82]
deepdive.pipeline.pipelines.cleanup: [cleanup]
