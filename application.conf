deepdive {

  db.default {
    driver   : "org.postgresql.Driver"
    url      : "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user     : ${PGUSER}
    password : ${PGPASSWORD}
    dbname   : ${DBNAME}
    host     : ${PGHOST}
    port     : ${PGPORT}
	gphost   : ${HOSTNAME}
	gpport   : 8888
	gppath   : ${LFS_DIR}/greenplum_gpfdist
	# start gpfdist server on the machine running the application with
	# `rungpcommand gpfdist -d $LFS_DIR/greenplum_gpfdist -p 8888 &`
  }

  # Parallel grounding
  inference.parallel_grounding: true

  # Specify a holdout fraction
  calibration.holdout_fraction: 0.1

  extraction.parallelism: 1

  # Put your extractors here
  extraction.extractors {

	# Find acronyms
	#find_acronyms: {
	#	before: ${APP_HOME}/code/delete_from_table.sh ${DBNAME} acronyms
	#	style: tsv_extractor
	#	input: """SELECT 
	#					doc_id,
	#					sent_id,
	#					array_to_string(wordidxs, '|^|'),
	#					array_to_string(words, '|^|'),
	#					array_to_string(poses, '|^|'),
	#					array_to_string(ners, '|^|'),
	#					array_to_string(lemmas, '|^|'),
	#					array_to_string(dep_paths, '|^|'),
	#					array_to_string(dep_parents, '|^|'),
	#					array_to_string(bounding_boxes, '|^|')
	#				FROM 
	#					sentences 
	#				"""
	#	output_relation: acronyms
	#	udf: ${APP_HOME}/code/find_acronyms.py
	#	#udf: util/extractor_input_writer.py /afs/cs.stanford.edu/u/rionda/lfs/sentences.tsv
	#	input_batch_size: ${SENTENCES_BATCH_SIZE}
	#	parallelism: ${PARALLELISM}
	#}

	# Empty the gene_mentions table
	clear_gene_mentions: {
		style: cmd_extractor
		cmd: ${APP_HOME}/code/delete_from_table.sh ${DBNAME} gene_mentions
	}

	# Extract gene mentions
	extract_gene_mentions: {
		style: tsv_extractor
		input: """
				WITH doc_acronyms AS (
					SELECT doc_id, acronym
					FROM acronyms
					GROUP BY doc_id, acronym)
				SELECT 
					t0.doc_id as doc_id,
					t0.sent_id as sent_id,
					array_to_string(t0.wordidxs, '|^|'),
					array_to_string(t0.words, '|^|'),
					array_to_string(t0.poses, '|^|'),
					array_to_string(t0.ners, '|^|'),
					array_to_string(t0.lemmas, '|^|'),
					array_to_string(t0.dep_paths, '|^|'),
					array_to_string(t0.dep_parents, '|^|'),
					array_to_string(t0.bounding_boxes, '|^|'),
					t1.acronym as acronym
				FROM 
					sentences t0
				LEFT JOIN 
					doc_acronyms t1 
				ON 
					t0.doc_id = t1.doc_id 
				AND 
					t1.acronym = ANY(t0.words);
				"""
		output_relation: gene_mentions
		udf: ${APP_HOME}/code/extract_gene_mentions.py 
		#udf: util/extractor_input_writer.py /afs/cs.stanford.edu/u/rionda/lfs/sentences.tsv
		dependencies: [find_acronyms, clear_gene_mentions]
		input_batch_size: ${SENTENCES_BATCH_SIZE}
		parallelism: ${PARALLELISM}
	}

	# Extract gene mentions from the geneRifs
	extract_geneRifs_mentions {
		type: tsv_extractor
		input: """SELECT 
						doc_id,
						sent_id,
						array_to_string(wordidxs, '|^|'),
						array_to_string(words, '|^|'),
						array_to_string(poses, '|^|'),
						array_to_string(ners, '|^|'),
						array_to_string(lemmas, '|^|'),
						array_to_string(dep_paths, '|^|'),
						array_to_string(dep_parents, '|^|'),
						array_to_string(bounding_boxes, '|^|'),
						gene
					FROM 
						generifs
					"""
		output_relation: gene_mentions
		udf: ${APP_HOME}/code/extract_geneRifs_mentions.py
		dependencies: [clear_gene_mentions]
		parallelism: 70
	}

	# Extract HPO terms mentions at the local level
	extract_hpoterm_mentions {
		before: ${APP_HOME}/code/delete_from_table.sh ${DBNAME} hpoterm_mentions
		style: tsv_extractor
		input: """SELECT 
						doc_id,
						sent_id,
						array_to_string(wordidxs, '|^|'),
						array_to_string(words, '|^|'),
						array_to_string(poses, '|^|'),
						array_to_string(ners, '|^|'),
						array_to_string(lemmas, '|^|'),
						array_to_string(dep_paths, '|^|'),
						array_to_string(dep_parents, '|^|'),
						array_to_string(bounding_boxes, '|^|')
					FROM 
						sentences 
					"""
		output_relation: hpoterm_mentions
		udf: ${APP_HOME}/code/extract_hpoterm_mentions.py 
		#udf: util/extractor_input_writer.py ${APP_HOME}/data/sentences-2k.tsv
		input_batch_size: ${SENTENCES_BATCH_SIZE}
		parallelism: ${PARALLELISM}
	}

	# Extract gene <-> HPO terms relations 
	gene_hpoterm_relations: {
		before: ${APP_HOME}/code/delete_from_table.sh ${DBNAME} gene_hpoterm_relations
		style: tsv_extractor
		input: """SELECT 
						sentences.doc_id,
						sentences.sent_id,
						array_to_string(sentences.wordidxs, '|^|'),
						array_to_string(sentences.words, '|^|'),
						array_to_string(sentences.poses, '|^|'),
						array_to_string(sentences.ners, '|^|'),
						array_to_string(sentences.lemmas, '|^|'),
						array_to_string(sentences.dep_paths, '|^|'),
						array_to_string(sentences.dep_parents, '|^|'),
						array_to_string(sentences.bounding_boxes, '|^|'),
						genes.entity,
						array_to_string(genes.wordidxs, '|^|'),
						hpoterms.entity,
						array_to_string(hpoterms.wordidxs, '|^|')
				FROM 
						gene_mentions genes, hpoterm_mentions hpoterms, sentences
				WHERE 
						genes.sent_id = hpoterms.sent_id
				AND		genes.sent_id = sentences.sent_id 
				AND		genes.doc_id = hpoterms.doc_id
				AND		genes.doc_id = sentences.doc_id
				AND		(genes.is_correct = True OR genes.is_correct IS NULL)
				AND		(hpoterms.is_correct = True OR hpoterms.is_correct IS NULL)
				"""
		output_relation: gene_hpoterm_relations
		#udf: ${APP_HOME}/code/gene_hpoterm_relations.py
		udf: util/extractor_input_writer.py ${LFS_DIR}/relations.tsv
		dependencies: [ extract_gene_mentions, extract_hpoterm_mentions ]
		parallelism: ${PARALLELISM}
	}

  }

  pipeline.run: debug
  pipeline.pipelines {
	debug: [ extract_gene_mentions, extract_hpoterm_mentions ]
  }

  # Put your variables here
  schema.variables {
	gene_mentions.is_correct: Boolean
	hpoterm_mentions.is_correct: Boolean
	#gene_hpoterm_relations.is_correct: Boolean
  }

  # Put your inference rules here
  inference.factors {

	# Check the gene mentions
	gene_mentions_is_correct {
		input_query: """
					SELECT 
						id as "gene_mentions.id",
						is_correct as "gene_mentions.is_correct",
						unnest(features) as "feature"
					FROM gene_mentions
					"""
		function: Imply(gene_mentions.is_correct)
		weight: "?(feature)"
	}

	# Check the HPO terms mentions
	hpoterm_mentions_is_correct {
		input_query: """
					SELECT 
						id as "hpoterm_mentions.id",
						is_correct as "hpoterm_mentions.is_correct",
						unnest(features) as "feature"
					FROM hpoterm_mentions
					"""
		function: Imply(hpoterm_mentions.is_correct)
		weight: "?(feature)"
	}
#
#	# Check the gene <-> HPO term relations mentions
#	gene_hpoterm_relations_is_correct {
#		input_query: """
#					SELECT 
#						id as "gene_hpoterm_relations.id",
#						is_correct as "gene_hpoterm_relations.is_correct",
#						unnest(features) as "gene_hpoterm_relations.feature"
#					FROM gene_hpoterm_relations
#					"""
#		# XXX (Matteo) Not clear to me why the following isn't IsTrue(). 
#		# This is taken from pharm
#		function: Imply(gene_hpoterm_relations.is_correct)
#		weight: "?(gene_hpoterm_relations.feature)"
#	}
  }
}
