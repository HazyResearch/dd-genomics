deepdive {

  db.default {
    driver   : "org.postgresql.Driver"
    url      : "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user     : ${PGUSER}
    password : ${PGPASSWORD}
    dbname   : ${DBNAME}
    host     : ${PGHOST}
    port     : ${PGPORT}
    gphost   : ${GPHOST}
    gpport   : ${GPPORT}
    gppath   : ${GPPATH}
  }

  # Parallel grounding for GreenPlum
  inference.parallel_grounding: ${PARALLEL_GROUNDING}

  # holdout fraction for calibration
  calibration.holdout_fraction: 0.1

  # Execute one extractor at a time (but we use parallelism for extractors)
  extraction.parallelism: 1


  ### PIPELINES ###
  pipeline.run: ${GDD_PIPELINE}
  pipeline.pipelines {
    none: [
    ]
    new_sentences: [
      sentences_to_input_format
    ]
    all_no_joint: [
      gene_extract_candidates, 
      gene_extract_features, 
      gene_inference,
      pheno_extract_candidates, 
      pheno_extract_features,
      pheno_inference,
      genepheno_extract_candidates,
      genepheno_extract_features,
      genepheno_inference
    ]
    all: [
      gene_extract_candidates, 
      gene_extract_features, 
      gene_inference,
      pheno_extract_candidates, 
      pheno_extract_features,
      pheno_inference,
      genepheno_extract_candidates,
      genepheno_extract_features,
      genepheno_inference,
      genepheno_to_gene,
      genepheno_to_pheno
    ]
    all_no_inference: [
      gene_extract_candidates, 
      gene_extract_features, 
      pheno_extract_candidates, 
      pheno_extract_features,
      genepheno_extract_candidates,
      genepheno_extract_features
    ]
    gene: [
      gene_extract_candidates, 
      gene_extract_features, 
      gene_inference
    ]
    gene_candidates: [
      gene_extract_candidates
    ]
    gene_features: [
      gene_extract_features
    ]
    gene_inference: [
      gene_inference
    ]
    gene_no_inference: [
      gene_extract_candidates, 
      gene_extract_features 
    ]
    pheno: [
      pheno_extract_candidates, 
      pheno_extract_features, 
      pheno_inference
    ]
    pheno_candidates: [
      pheno_extract_candidates
    ]
    pheno_features: [
      pheno_extract_features
    ]
    pheno_inference: [
      pheno_inference
    ]
    pheno_no_inference: [
      pheno_extract_candidates, 
      pheno_extract_features
    ] 
    gene_and_pheno: [
      gene_extract_candidates, 
      gene_extract_features, 
      gene_inference
      pheno_extract_candidates, 
      pheno_extract_features, 
      pheno_inference
    ] 
    genepheno: [
      genepheno_extract_candidates,
      genepheno_extract_features,
      genepheno_inference,
      genepheno_to_gene,
      genepheno_to_pheno
    ]
    genepheno_no_joint: [
      genepheno_extract_candidates,
      genepheno_extract_features,
      genepheno_inference
    ]
    genepheno_no_inference: [
      genepheno_extract_candidates,
      genepheno_extract_features
    ]
  }


### EXTRACTORS ###
  extraction.extractors {

    sentences_to_input_format: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS sentences_input CASCADE;
        CREATE TABLE 
          sentences_input
        AS SELECT
          doc_id,
          sent_id,
          array_to_string(wordidxs, '|^|') AS wordidxs,
          array_to_string(words, '|^|') AS words,
          array_to_string(poses, '|^|') AS poses,
          array_to_string(ners, '|^|') AS ners,
          array_to_string(lemmas, '|^|') AS lemmas,
          array_to_string(dep_paths, '|^|') AS dep_paths,
          array_to_string(dep_parents, '|^|') AS dep_parents,
          array_to_string(bounding_boxes, '|^|') AS bounding_boxes
        FROM
          sentences;
      """
    }

    gene_extract_candidates: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} gene_mentions
      style: tsv_extractor
      input: """
        SELECT
          doc_id,
          sent_id,
          words,
          lemmas,
          poses,
          ners
        FROM 
          sentences_input
      """
      output_relation: gene_mentions
      udf: ${APP_HOME}/code/gene_extract_candidates.py
      parallelism: ${PARALLELISM}
    }

    gene_extract_features: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} gene_features
      style: tsv_extractor
      input: """
        SELECT 
          s.doc_id,
          s.sent_id,
          s.words,
          s.lemmas,
          s.poses,
          s.ners,
          s.dep_paths,
          s.dep_parents,
          m.mention_id,
          array_to_string(m.wordidxs, '|^|')
        FROM 
          sentences_input s,
          gene_mentions m
        WHERE 
          s.doc_id = m.doc_id
          AND s.sent_id = m.sent_id
      """
      output_relation: gene_features
      udf: ${APP_HOME}/code/gene_extract_features.py
      parallelism: ${PARALLELISM}
      dependencies: [gene_extract_candidates]
    }

    # NOTE: input_batch_size extended because Robin thought that the init cost was highest
    # TODO -> re-evaluate this / test..?   
    pheno_extract_candidates: {
      before: ${APP_HOME}/util/pheno_extract_candidates_before.sh
      style: tsv_extractor
      input: """
        SELECT 
          doc_id,
          sent_id,
          words,
          lemmas,
          poses,
          ners
        FROM 
          sentences_input
      """
      output_relation: pheno_mentions
      udf: ${APP_HOME}/code/pheno_extract_candidates.py
      parallelism: ${PARALLELISM}
      input_batch_size: 100000
    }

    pheno_extract_features: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} pheno_features
      style: tsv_extractor
      input: """
        SELECT 
          s.doc_id,
          s.sent_id,
          s.words,
          s.lemmas,
          s.poses,
          s.ners,
          s.dep_paths,
          s.dep_parents,
          m.mention_id,
          array_to_string(m.wordidxs, '|^|')
        FROM 
          sentences_input s,
          pheno_mentions m
        WHERE 
          s.doc_id = m.doc_id 
          AND s.sent_id = m.sent_id
      """
      output_relation: pheno_features
      udf: ${APP_HOME}/code/pheno_extract_features.py
      parallelism: ${PARALLELISM}
      dependencies: [pheno_extract_candidates]
    }
    
    # HACK[Alex]: hard-coding exclusion of negatively-supervised G, P
    genepheno_extract_candidates: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} genepheno_relations
      style: tsv_extractor
      input: """
        SELECT
          s.doc_id,
          s.sent_id,
          s.words,
          s.lemmas,
          s.poses,
          s.dep_paths,
          s.dep_parents,
          g.mention_ids AS gene_mention_ids,
          g.entities AS gene_entities,
          g.wordidxs AS gene_wordidxs,
          p.mention_ids AS pheno_mention_ids,
          p.entities AS pheno_entities,
          p.wordidxs AS pheno_wordidxs
        FROM
          sentences_input s,
          (
            SELECT
              doc_id,
              sent_id,
              ARRAY_AGG(array_to_string(mention_id, '|^|')) AS mention_ids,
              ARRAY_AGG(array_to_string(entity, '|^|')) AS entities,
              ARRAY_AGG(array_to_string(wordidxs, '|~|')) AS wordidxs
            FROM
              gene_mentions
            WHERE
              is_correct IS NULL OR is_correct IS TRUE
            GROUP BY
              doc_id, sent_id
          ) g,
          (
            SELECT
              doc_id,
              sent_id,
              ARRAY_AGG(array_to_string(mention_id, '|^|')) AS mention_ids,
              ARRAY_AGG(array_to_string(entity, '|^|')) AS entities,
              ARRAY_AGG(array_to_string(wordidxs, '|~|')) AS wordidxs
            FROM
              pheno_mentions
            WHERE
              is_correct IS NULL OR is_correct IS TRUE
            GROUP BY
              doc_id, sent_id
          ) p
        WHERE
          s.doc_id = g.doc_id
          AND s.sent_id = g.sent_id
          AND s.doc_id = p.doc_id
          AND s.sent_id = p.sent_id
        """
      output_relation: genepheno_relations
      udf: ${APP_HOME}/code/genepheno_extract_candidates.py
      parallelism: ${PARALLELISM}
      dependencies: [gene_extract_candidates, pheno_extract_candidates]
    }
    
    genepheno_extract_features: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} genepheno_features
      style: tsv_extractor
      input: """SELECT
              r.relation_id,
              r.doc_id,
              r.sent_id,
              r.gene_mention_id,
              r.gene_wordidxs,
              r.pheno_mention_id,
              r.pheno_wordidxs,
              s.words,
              s.lemmas,
              s.poses,
              s.ners,
              s.dep_paths,
              s.dep_parents,
              s.wordidxs
           FROM
              genepheno_relations r,
              sentences_input s
          WHERE
              r.doc_id = s.doc_id
              AND r.sent_id = s.sent_id
        """
      output_relation: genepheno_features
      udf: ${APP_HOME}/code/genepheno_extract_features.py
      parallelism: ${PARALLELISM}
      dependencies: [genepheno_extract_candidates]
    }
  }


### SCHEMA ###

  # Random variables
  schema.variables {
    gene_mentions.is_correct: Boolean
    pheno_mentions.is_correct: Boolean
    genepheno_relations.is_correct: Boolean
  }


### INFERENCE RULES ###

  # Inference rules
  inference.factors {
    gene_inference {
      input_query = """
        SELECT 
          gm.id as "gene_mentions.id",
          gm.is_correct as "gene_mentions.is_correct",
          gf.feature as "gene_features.feature"
        FROM
          gene_mentions gm,
          gene_features gf
        WHERE 
          gm.mention_id = gf.mention_id;
      """
      function: IsTrue(gene_mentions.is_correct)
      weight: "?(gene_features.feature)"
    }

    pheno_inference {
      input_query = """
        SELECT 
          pm.id as "pheno_mentions.id",
          pm.is_correct as "pheno_mentions.is_correct",
          pf.feature as "pheno_features.feature"
        FROM 
          pheno_mentions pm, 
          pheno_features pf
        WHERE 
          pm.mention_id = pf.mention_id;
      """
      function: IsTrue(pheno_mentions.is_correct)
      weight: "?(pheno_features.feature)"
    }

    genepheno_inference {
      input_query = """
        SELECT 
          gpr.id as "genepheno_relations.id",
          gpr.is_correct as "genepheno_relations.is_correct",
          gpf.feature as "genepheno_features.feature"
        FROM 
          genepheno_relations gpr,
          genepheno_features gpf
        WHERE 
          gpr.relation_id = gpf.relation_id;
      """
      function: IsTrue(genepheno_relations.is_correct)
      weight: "?(genepheno_features.feature)"
    }

    genepheno_to_gene {
      input_query: """
        SELECT
          gp.id as "genepheno_relations.id",
          gp.is_correct as "genepheno_relations.is_correct",
          gm.id as "gene_mentions.id",
          gm.is_correct as "gene_mentions.is_correct"
        FROM
          genepheno_relations gp,
          gene_mentions gm
        WHERE
          gp.doc_id = gm.doc_id AND
          gp.gene_mention_id = gm.mention_id
        """
      function: "Imply(genepheno_relations.is_correct, gene_mentions.is_correct)"
      weight: "?"
    }

    genepheno_to_pheno {
      input_query: """
        SELECT
          gp.id as "genepheno_relations.id",
          gp.is_correct as "genepheno_relations.is_correct",
          pm.id as "pheno_mentions.id",
          pm.is_correct as "pheno_mentions.is_correct"
        FROM
          genepheno_relations gp,
          pheno_mentions pm
        WHERE
          gp.doc_id = pm.doc_id AND
          gp.pheno_mention_id = pm.mention_id
        """
      function: "Imply(genepheno_relations.is_correct, pheno_mentions.is_correct)"
      weight: "?"
    }
  }

  # NOTE: the --sample_evidence flag needs the sampler binary from the sample_evidence
  # branch of the sampler repo to be in deepdive/util/; if not, just remove this flag
  sampler.sampler_args: "-l 300 -s 1 -i 500 --alpha 0.1 --diminish 0.99 --sample_evidence"
}

