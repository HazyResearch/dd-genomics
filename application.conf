deepdive {

  db.default {
    driver   : "org.postgresql.Driver"
    url      : "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user     : ${PGUSER}
    password : ${PGPASSWORD}
    dbname   : ${DBNAME}
    host     : ${PGHOST}
    port     : ${PGPORT}
	gphost   : ${GPHOST}
	gpport   : ${GPPORT}
	gppath   : ${GPPATH}
	# start gpfdist server on the machine running the application with
	# `rungpcommand 'gpfdist -d /lfs/raiders4/0/rionda/greenplum_gpfdist -p 8888'`
  }

  # Parallel grounding for GreenPlum
  inference.parallel_grounding: true

  # holdout fraction for calibration
  calibration.holdout_fraction: 0.1

  # Execute one extractor at a time (but we use parallelism for extractors)
  extraction.parallelism: 1

  # Extractors
  extraction.extractors {

### ACRONYMS ###

	# Find acronyms in documents
	find_acronyms: {
		before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} acronyms
		style: tsv_extractor
		input: """SELECT
					doc_id,
					array_to_string(array_accum(sent_id), '|^|'),
					array_to_string(array_accum(wordidxs), '!~!'),
					array_to_string(array_accum(words), '!~!'),
					array_to_string(array_accum(poses), '!~!'),
					array_to_string(array_accum(ners), '!~!'),
					array_to_string(array_accum(lemmas), '!~!'),
					array_to_string(array_accum(dep_paths), '!~!'),
					array_to_string(array_accum(dep_parents), '!~!'),
					array_to_string(array_accum(bounding_boxes), '!~!')
				FROM
					sentences_input
				GROUP BY doc_id
				"""
		output_relation: acronyms
		udf: ${APP_HOME}/code/find_acronyms.py
		parallelism: ${PARALLELISM}
	}

### GENES ###

	# Extract gene mention candidates
	extract_gene_mentions: {
		before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} gene_mentions
		style: tsv_extractor
		input: """SELECT * FROM sentences_input"""
		output_relation: gene_mentions
		udf: ${APP_HOME}/code/extract_gene_mentions.py
		parallelism: ${PARALLELISM}
	}

	# Supervise the gene mention candidates using the acronyms
	gene_supervision_acronyms: {
		style: sql_extractor
		sql: """UPDATE gene_mentions
				SET 
					g.is_correct = a.is_correct
				FROM 
					gene_mentions g, doc_acronyms a
				WHERE 
					a.is_correct IS NOT NULL
				AND
					g.type = 'GENE'
				AND
					g.doc_id = a.doc_id
				AND
					g.words[1] = a.acronym
			"""
		dependencies: [find_acronyms, extract_gene_mentions]
	}

	# For each supervised gene mention candidate, add an unsupervised copy
	add_unsuper_dup_genes: {
		style: sql_extractor
		sql: """INSERT INTO gene_mentions
				SELECT
					id, 
					doc_id, 
					sent_id, 
					wordidxs, 
					mention_id || '_UNSUP',
					type || '_UNSUP',
					entity,
					words,
					NULL,
					features
				FROM
					gene_mentions
				WHERE
					is_correct IS NOT NULL
				AND type <> 'GENE_SUP_contr_2'
				AND type <> 'GENE_SUP_contr_1'
				"""
		dependencies: [gene_supervision_acronyms, gene_hpoterm_relations]
	}

	# Extract gene mentions from the geneRifs
	extract_geneRifs_mentions: {
		before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} generifs_mentions
		style: tsv_extractor
		input: """SELECT
						doc_id,
						sent_id,
						array_to_string(wordidxs, '|^|'),
						array_to_string(words, '|^|'),
						array_to_string(poses, '|^|'),
						array_to_string(ners, '|^|'),
						array_to_string(lemmas, '|^|'),
						array_to_string(dep_paths, '|^|'),
						array_to_string(dep_parents, '|^|'),
						array_to_string(bounding_boxes, '|^|'),
						gene
					FROM
						generifs
					"""
		output_relation: generifs_mentions
		udf: ${APP_HOME}/code/extract_geneRifs_mentions.py
		parallelism: ${PARALLELISM}
	}

	# Add the geneRifs extractions to the gene mentions table
	add_geneRifs_mentions: {
		style: sql_extractor
		sql: """INSERT INTO gene_mentions SELECT * FROM generifs_mentions"""
		dependencies = [extract_geneRifs_mentions, add_unsuper_dup_genes]
	}

### HPOTERMS ###

	# Extract HPO terms mentions
	extract_hpoterm_mentions {
		before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} hpoterm_mentions
		style: tsv_extractor
		input: """SELECT * FROM sentences_input"""
		output_relation: hpoterm_mentions
		udf: ${APP_HOME}/code/extract_hpoterm_mentions.py
		parallelism: ${PARALLELISM}
	}

	# For each supervised hpoterm mention candidate, add an unsupervised copy
	# We actually do it only for candidates that are not genes or random words,
	# which we know are false.
	add_unsuper_dup_hpoterms: {
		style: sql_extractor
		sql: """INSERT INTO hpoterm_mentions
				SELECT
					id, 
					doc_id, 
					sent_id, 
					wordidxs, 
					mention_id || '_UNSUP',
					type || '_UNSUP',
					entity,
					words,
					NULL,
					features
				FROM
					hpoterm_mentions
				WHERE
					is_correct IS NOT NULL
				AND
					type <> 'HPOTERM_SUP_gene'
				AND
					type <> 'HPOTERM_SUP_rand'
				"""
		dependencies: [extract_hpoterm_mentions, gene_hpoterm_relations]
	}

### GENE / HPOTERM ###

	# Extract gene <-> HPO terms relations
	gene_hpoterm_relations: {
		before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} gene_hpoterm_relations
		style: tsv_extractor
		input: """ WITH g AS (
						SELECT 
							doc_id,
							sent_id,
							array_to_string(array_accum(genes.entity), '|^|') as entities,
							array_to_string(array_accum(array_to_string(genes.wordidxs, '|^|')), '!~!') as wordidxs, 
							array_to_string(array_accum(CASE WHEN genes.is_correct = true THEN 't' WHEN genes.is_correct = false THEN 'f' ELSE 'n' END), '|^|') as is_corrects,
							array_to_string(array_accum(genes.type), '|^|') as types
							FROM gene_mentions genes
							group by doc_id, sent_id
						), h AS (
						SELECT
							doc_id,
							sent_id,
							array_to_string(array_accum(hpoterms.entity), '|^|') as entities, 
							array_to_string(array_accum(array_to_string(hpoterms.wordidxs, '|^|')), '!~!') as wordidxs,
							array_to_string(array_accum(CASE WHEN hpoterms.is_correct = true THEN 't' WHEN hpoterms.is_correct = false THEN 'f' ELSE 'n' END), '|^|') as is_corrects,
							array_to_string(array_accum(hpoterms.type), '|^|') as types
							FROM hpoterm_mentions hpoterms
							group by doc_id, sent_id
						)
					SELECT 
							sentences_input.doc_id,
							sentences_input.sent_id,
							max(sentences_input.wordidxs),
							max(sentences_input.words),
							max(sentences_input.poses),
							max(sentences_input.ners),
							max(sentences_input.lemmas),
							max(sentences_input.dep_paths),
							max(sentences_input.dep_parents),
							max(sentences_input.bounding_boxes),
							max(g.entities),
							max(g.wordidxs),
							max(g.is_corrects),
							max(g.types),
							max(h.entities),
							max(h.wordidxs),
							max(h.is_corrects),
							max(h.types)
					FROM
							g, h, sentences_input
					WHERE
							sentences_input.doc_id = h.doc_id
					AND		sentences_input.sent_id = h.sent_id
					AND		g.doc_id = sentences_input.doc_id
					AND		g.sent_id = sentences_input.sent_id
					GROUP BY sentences_input.doc_id, sentences_input.sent_id
				"""
		output_relation: gene_hpoterm_relations
		udf: ${APP_HOME}/code/gene_hpoterm_relations.py
		dependencies: [gene_supervision_acronyms, extract_hpoterm_mentions]
		parallelism: ${PARALLELISM}
	}

	# For each supervised gene/hpoterm relation candidate, add an unsupervised
	# copy
	add_unsuper_dup_genehpoterms: {
		style: sql_extractor
		sql: """INSERT INTO gene_hpoterm_relations
				SELECT
					id,
					doc_id,
					sent_id_1,
					sent_id_2,
					relation_id || '_UNSUP',
					type || '_UNSUP',
					mention_id_1,
					mention_id_2,
					wordidxs_1,
					wordidxs_2,
					words_1,
					words_2,
					NULL,
					features
				FROM
					gene_hpoterm_relations
				WHERE
					is_correct IS NOT NULL
				"""
		dependencies: [gene_hpoterm_relations]
	}
  }

### PIPELINES ###

  # Pipeline: select which extractors / factors to run
  #pipeline.run: debug
  pipeline.pipelines {
	# Run only some extractors / factors
	debug: [classify_gene_mentions, classify_hpoterm_mentions, classify_gene_hpoterm_relations_features]
	# Acronyms
	acronyms: [find_acronyms]
	# Genes
	genes: [extract_gene_mentions, gene_supervision_acronyms, add_unsuper_dup_genes, extract_geneRifs_mentions, add_geneRifs_mentions, classify_gene_mentions]
	# HPOterms
	hpoterms: [extract_hpoterm_mentions, add_unsuper_dup_hpoterms, classify_hpoterm_mentions]
	# Gene/Hpoterm
	gene_hpoterm: [gene_hpoterm_relations, add_unsuper_dup_genehpoterms, classify_gene_hpoterm_relations_features]
	# All extractors / factors
	all: [ find_acronyms, extract_gene_mentions, gene_supervision_acronyms, add_unsuper_dup_genes, extract_geneRifs_mentions, add_geneRifs_mentions, classify_gene_mentions, extract_hpoterm_mentions, add_unsuper_dup_hpoterms, classify_hpoterm_mentions, gene_hpoterm_relations, add_unsuper_dup_genehpoterms, classify_gene_hpoterm_relations_features]
  }

### SCHEMA ###

  # Random variables
  schema.variables {
	gene_mentions.is_correct: Boolean
	hpoterm_mentions.is_correct: Boolean
	gene_hpoterm_relations.is_correct: Boolean
  }

### INFERENCE RULES ###

  # Inference rules
  inference.factors {

	# Classify the gene mentions
	classify_gene_mentions {
		input_query: """
              SELECT id as "gene_mentions.id",
                     is_correct as "gene_mentions.is_correct" ,
                     unnest(features) as "feature"
              FROM gene_mentions
              """
              function: IsTrue(gene_mentions.is_correct)
		weight: "?(feature)"
	}

	# Conditional random field for gene mentions
	#factor_skip_chain_crf {
	#  input_query: """select *
	#	from (select gene_mentions_1.id as "gene_mentions.1.id",
	#	gene_mentions_2.id as "gene_mentions.2.id", gene_mentions_1.is_correct
	#	as "gene_mentions.1.is_correct", gene_mentions_2.is_correct as
	#	"gene_mentions.2.is_correct", row_number() over (partition by
	#	gene_mentions_1.id) as rn from gene_mentions gene_mentions_1,
	#	gene_mentions gene_mentions_2 where gene_mentions_1.doc_id = gene_mentions_2.doc_id and
	#	gene_mentions_1.words = gene_mentions_2.words and gene_mentions_1.id <
	#	gene_mentions_2.id) scrf where scrf.rn = 1""" 
	#  function: "Equal(gene_mentions.1.is_correct, gene_mentions.2.is_correct)"
	#  weight: "?"
	#}

	# Classify the HPOterm mentions
	classify_hpoterm_mentions {
		input_query: """
					SELECT
						id as "hpoterm_mentions.id",
						is_correct as "hpoterm_mentions.is_correct",
						unnest(features) as "feature"
					FROM hpoterm_mentions
					"""
		function: IsTrue(hpoterm_mentions.is_correct)
		weight: "?(feature)"
	}

	# Classify the gene <-> HPO term relation mentions using the features
	classify_gene_hpoterm_relations_features {
		input_query: """
					SELECT
						id as "gene_hpoterm_relations.id",
						is_correct as "gene_hpoterm_relations.is_correct",
						unnest(features) as "feature"
					FROM gene_hpoterm_relations
					"""
		function: IsTrue(gene_hpoterm_relations.is_correct)
		weight: "?(feature)"
	}

	# Classify the gene <-> HPO term relation mentions using the correctness of
	# the gene mentions composing the relations
	#classify_gene_hpoterm_relations_gene {
	#	input_query: """
	#				SELECT
	#					t0.id as "gene_hpoterm_relations.id",
	#					t0.is_correct as "gene_hpoterm_relations.is_correct",
	#					t1.id as "gene_mentions.id",
	#					t1.is_correct as "gene_mentions.is_correct"
	#				FROM gene_hpoterm_relations t0, gene_mentions t1
	#				WHERE t0.mention_id_1 = t1.mention_id;
	#				"""
	#	#function: "Imply(!gene_mentions.is_correct, !gene_hpoterm_relations.is_correct)"
	#	function: "And(!gene_mentions.is_correct, gene_hpoterm_relations.is_correct)"
	#	weight: "-10"
    #}

	# Classify the gene <-> HPO term relation mentions using the correctness of
	# the HPO term mentions composing the relations
	#classify_gene_hpoterm_relations_hpoterm {
	#	input_query: """
	#				SELECT
	#					t0.id as "gene_hpoterm_relations.id",
	#					t0.is_correct as "gene_hpoterm_relations.is_correct",
	#					t1.id as "hpoterm_mentions.id",
	#					t1.is_correct as "hpoterm_mentions.is_correct"
	#				FROM gene_hpoterm_relations t0, hpoterm_mentions t1
	#				WHERE t0.mention_id_2 = t1.mention_id;
	#				"""
	#	#function: "Imply(!hpoterm_mentions.is_correct, !gene_hpoterm_relations.is_correct)"
	#	function: "And(!hpoterm_mentions.is_correct, gene_hpoterm_relations.is_correct)"
	#	weight: "-10"
	#}
  }
}

