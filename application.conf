deepdive {

  db.default {
    driver   : "org.postgresql.Driver"
    url      : "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user     : ${PGUSER}
    password : ${PGPASSWORD}
    dbname   : ${DBNAME}
    host     : ${PGHOST}
    port     : ${PGPORT}
	gphost   : ${GPHOST}
	gpport   : ${GPPORT}
	gppath   : ${GPPATH}
	# start gpfdist server on the machine running the application with
	# `rungpcommand 'gpfdist -d /lfs/raiders4/0/rionda/greenplum_gpfdist -p 8888'`
  }

  # Parallel grounding
  inference.parallel_grounding: true

  # Specify a holdout fraction
  calibration.holdout_fraction: 0.1

  extraction.parallelism: 1

  # Put your extractors here
  extraction.extractors {

	# Find acronyms
	find_acronyms: {
		before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} acronyms
		style: tsv_extractor
		input: """SELECT * FROM sentences_input_20k
					"""
		output_relation: acronyms
		udf: ${APP_HOME}/code/find_acronyms.py
		parallelism: ${PARALLELISM}
	}

	# Create doc-acronyms table, to be used in extract_gene_mentions
	# The table contains one row for each combination of (doc_id,
	# acronym), containing these two fields and a string of definitions for
	# the acronym defined in the document. The definitions are separated by
	# '|^|'.
	create_doc_acronyms {
		before: ${APP_HOME}/code/drop_table.sh ${DBNAME} doc_acronyms
		style: sql_extractor
		sql: """CREATE TABLE
						doc_acronyms
				AS
				SELECT
						doc_id,
						acronym,
						array_to_string(array_agg(DISTINCT lower(definition)), '|^|') as definitions
				FROM
						acronyms
				GROUP BY doc_id, acronym
				"""
		dependencies: [ find_acronyms ]
	}

	# Extract gene mentions from the geneRifs
	extract_geneRifs_mentions {
		before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} generifs_mentions
		style: tsv_extractor
		input: """SELECT
						doc_id,
						sent_id,
						array_to_string(wordidxs, '|^|'),
						array_to_string(words, '|^|'),
						array_to_string(poses, '|^|'),
						array_to_string(ners, '|^|'),
						array_to_string(lemmas, '|^|'),
						array_to_string(dep_paths, '|^|'),
						array_to_string(dep_parents, '|^|'),
						array_to_string(bounding_boxes, '|^|'),
						gene
					FROM
						generifs
					"""
		output_relation: generifs_mentions
		udf: ${APP_HOME}/code/extract_geneRifs_mentions.py
		parallelism: ${PARALLELISM}
	}

	# Empty the gene_mentions table and add the extractions from the geneRifs
	add_geneRifs_mentions: {
		style: sql_extractor
		sql: """TRUNCATE TABLE gene_mentions;
				INSERT INTO gene_mentions SELECT * FROM generifs_mentions
			"""
		cmd: ${APP_HOME}/code/truncate_table.sh ${DBNAME} gene_mentions
		dependencies = [ extract_geneRifs_mentions]
	}

	# Create and populate the input table to the gene_mentions extractor
	create_gene_mentions_input: {
		style: sql_extractor
		sql: """DROP TABLE IF EXISTS gene_mentions_input;
				CREATE TABLE gene_mentions_input
				AS
				SELECT
					t0.doc_id as doc_id,
					t0.sent_id as sent_id,
					max(array_to_string(t0.wordidxs, '|^|')) as wordidxs,
					max(array_to_string(t0.words, '|^|')) as words,
					max(array_to_string(t0.poses, '|^|')) as poses,
					max(array_to_string(t0.ners, '|^|')) as ners,
					max(array_to_string(t0.lemmas, '|^|')) as lemmas,
					max(array_to_string(t0.dep_paths, '|^|')) as dep_paths,
					max(array_to_string(t0.dep_parents, '|^|')) as dep_parents,
					max(array_to_string(t0.bounding_boxes, '|^|')) as bounding_boxes,
					array_to_string(array_accum(t1.acronym), '|^|') as acronyms,
					array_to_string(array_accum(t1.definitions), '|^^|') as definitions
				FROM
					sentences t0
				LEFT JOIN
					doc_acronyms t1
				ON
					t0.doc_id = t1.doc_id
				AND
					t1.acronym = ANY(t0.words)
				GROUP BY
					t0.doc_id, t0.sent_id
				"""
		dependencies: [ create_doc_acronyms ]
	}

	# Extract gene mentions
	extract_gene_mentions: {
		style: tsv_extractor
		input: """
				SELECT * FROM gene_mentions_input
				"""
		output_relation: gene_mentions
		udf: ${APP_HOME}/code/extract_gene_mentions.py
		dependencies: [add_geneRifs_mentions, create_gene_mentions_input]
		parallelism: ${PARALLELISM}
	}

	# Extract HPO terms mentions at the local level
	extract_hpoterm_mentions {
		before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} hpoterm_mentions
		style: tsv_extractor
		input: """SELECT * FROM sentences_input_20k
					"""
		output_relation: hpoterm_mentions
		udf: ${APP_HOME}/code/extract_hpoterm_mentions.py
		input_batch_size: ${SENTENCES_BATCH_SIZE}
		parallelism: ${PARALLELISM}
	}

	# Extract gene <-> HPO terms relations
	gene_hpoterm_relations: {
		before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} gene_hpoterm_relations
		style: tsv_extractor
		input: """SELECT 
						sentences_input.doc_id,
						sentences_input.sent_id,
						sentences_input.wordidxs,
						sentences_input.words,
						sentences_input.poses,
						sentences_input.ners,
						sentences_input.lemmas,
						sentences_input.dep_paths,
						sentences_input.dep_parents,
						sentences_input.bounding_boxes,
						genes.entity,
						array_to_string(genes.wordidxs, '|^|'),
						genes.is_correct,
						hpoterms.entity,
						array_to_string(hpoterms.wordidxs, '|^|'),
						hpoterms.is_correct
				FROM
						gene_mentions genes, hpoterm_mentions hpoterms,
						sentences_input
				WHERE
						genes.doc_id = hpoterms.doc_id
				AND		genes.doc_id = sentences_input.doc_id
				AND		genes.sent_id = hpoterms.sent_id
				AND		genes.sent_id = sentences_input.sent_id
				"""
		output_relation: gene_hpoterm_relations
		udf: ${APP_HOME}/code/gene_hpoterm_relations.py
		dependencies: [ extract_gene_mentions, add_geneRifs_mentions, extract_hpoterm_mentions ]
		parallelism: ${PARALLELISM}
	}

  }

  pipeline.run: debug
  pipeline.pipelines {
	debug: [ classify_gene_mentions, factor_skip_chain_crf, classify_hpoterm_mentions, classify_gene_hpoterm_relations_features]
  }

  # Put your variables here
  schema.variables {
	gene_mentions.is_correct: Boolean
	hpoterm_mentions.is_correct: Boolean
	gene_hpoterm_relations.is_correct: Boolean
  }

  # Put your inference rules here
  inference.factors {

	# Classify the gene mentions
	classify_gene_mentions {
		input_query: """
              SELECT id as "gene_mentions.id",
                     is_correct as "gene_mentions.is_correct" ,
                     unnest(features) as "feature"
              FROM gene_mentions
              """
              function: IsTrue(gene_mentions.is_correct)
		weight: "?(feature)"
	}

	factor_skip_chain_crf {
	  input_query: """select *
		from (select gene_mentions_1.id as "gene_mentions.1.id",
		gene_mentions_2.id as "gene_mentions.2.id", gene_mentions_1.is_correct
		as "gene_mentions.1.is_correct", gene_mentions_2.is_correct as
		"gene_mentions.2.is_correct", row_number() over (partition by
		gene_mentions_1.id) as rn from gene_mentions gene_mentions_1,
		gene_mentions gene_mentions_2 where gene_mentions_1.doc_id = gene_mentions_2.doc_id and
		gene_mentions_1.words = gene_mentions_2.words and gene_mentions_1.id <
		gene_mentions_2.id) scrf where scrf.rn = 1""" 
	  function: "Equal(gene_mentions.1.is_correct, gene_mentions.2.is_correct)"
	  weight: "?"
	}



	# Classify the HPO terms mentions
	classify_hpoterm_mentions {
		input_query: """
					SELECT
						id as "hpoterm_mentions.id",
						is_correct as "hpoterm_mentions.is_correct",
						unnest(features) as "feature"
					FROM hpoterm_mentions
					"""
		function: IsTrue(hpoterm_mentions.is_correct)
		weight: "?(feature)"
	}

	# Factor to help classify the gene <-> HPO term relation mentions using the
	# relation features
	classify_gene_hpoterm_relations_features {
		input_query: """
					SELECT
						id as "gene_hpoterm_relations.id",
						is_correct as "gene_hpoterm_relations.is_correct",
						unnest(features) as "feature"
					FROM gene_hpoterm_relations
					"""
		function: IsTrue(gene_hpoterm_relations.is_correct)
		weight: "?(feature)"
	}

	# Factor to help classify the gene <-> HPO term relation mentions using the
	# correctness of the gene mentions composing the relations
	#classify_gene_hpoterm_relations_gene {
	#	input_query: """
	#				SELECT
	#					t0.id as "gene_hpoterm_relations.id",
	#					t0.is_correct as "gene_hpoterm_relations.is_correct",
	#					t1.id as "gene_mentions.id",
	#					t1.is_correct as "gene_mentions.is_correct"
	#				FROM gene_hpoterm_relations t0, gene_mentions t1
	#				WHERE t0.mention_id_1 = t1.mention_id;
	#				"""
	#	#function: "Imply(!gene_mentions.is_correct, !gene_hpoterm_relations.is_correct)"
	#	function: "And(!gene_mentions.is_correct, gene_hpoterm_relations.is_correct)"
	#	weight: "-10"
    #}

	# Factor to help classify the gene <-> HPO term relation mentions using the
	# correctness of the HPO term mentions composing the relations
	#classify_gene_hpoterm_relations_hpoterm {
	#	input_query: """
	#				SELECT
	#					t0.id as "gene_hpoterm_relations.id",
	#					t0.is_correct as "gene_hpoterm_relations.is_correct",
	#					t1.id as "hpoterm_mentions.id",
	#					t1.is_correct as "hpoterm_mentions.is_correct"
	#				FROM gene_hpoterm_relations t0, hpoterm_mentions t1
	#				WHERE t0.mention_id_2 = t1.mention_id;
	#				"""
	#	#function: "Imply(!hpoterm_mentions.is_correct, !gene_hpoterm_relations.is_correct)"
	#	function: "And(!hpoterm_mentions.is_correct, gene_hpoterm_relations.is_correct)"
	#	weight: "-10"
	#}
  }
}

