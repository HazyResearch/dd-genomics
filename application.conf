deepdive {

  db.default {
    driver   : "org.postgresql.Driver"
    url      : "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user     : ${PGUSER}
    password : ${PGPASSWORD}
    dbname   : ${DBNAME}
    host     : ${PGHOST}
    port     : ${PGPORT}
    gphost   : ${GPHOST}
    gpport   : ${GPPORT}
    gppath   : ${GPPATH}
    gpload   : ${GPLOAD}
  }

  # Parallel grounding for GreenPlum
  inference.parallel_grounding: ${PARALLEL_GROUNDING}

  # holdout fraction for calibration
  calibration.holdout_fraction: 0.1

  # Execute one extractor at a time (but we use parallelism for extractors)
  extraction.parallelism: 1

  ### PIPELINES ###
  pipeline.run: ${GDD_PIPELINE}
  pipeline.pipelines {
    none: [
    ]
    preprocess: [
      serialize_sentences
    ]
    load_allowed_phenos: [
      load_allowed_phenos
    ]
    hgvs_hpo: [
      load_hgvs_hpo
    ]
    charite: [
      load_charite,
      load_charite_canon
    ]
    holdout: [
      load_genepheno_holdout_set
      load_genepheno_holdout_labels
    ]
    non_gene_acronyms: [
      gene_extract_candidates, 
      non_gene_acronyms_extract_candidates,
      non_gene_acronyms_delete_candidates,
      get_genepheno_pairs,
    ]
    load_sequences: [
      # load_ensembl_protein_sequences,
      # load_ensembl_gene_sequences,
      # genevariant_supervise_matching_proteins,
      genevariant_supervise_matching_coding_genes
    ]
    variant: [
      load_hg19_ensGene,
      all_gene_names_to_transcripts,
      variant_extract_candidates,
      get_genevariant_pairs,
      genevariant_extract_candidates,
      variant_filter_candidates,
      variant_extract_features,
      variant_inference,
      genevariant_inference
    ]
    variant2: [
      get_genevariant_pairs,
      serialize_genevariant_pairs_split
    ]
    pheno_acronyms_insert_candidates: [
      pheno_acronyms_extract_candidates,
      pheno_acronyms_aggregate_candidates,
      pheno_acronyms_insert_candidates,
    ]
    precision: [
      load_genepheno_holdout_set,
      load_genepheno_holdout_labels,
      precision
    ]
    full_pipeline_gp: [
      load_allowed_phenos,
      load_genes,
      load_genepheno_holdout_set,
      load_genepheno_holdout_labels,
      load_hpo_abnormalities,
      load_charite,
      load_charite_canon,
      load_hgvs_hpo,
      cleanup_doc_ids1,
      cleanup_doc_ids2,
      gene_extract_candidates, 
      non_gene_acronyms_extract_candidates,
      non_gene_acronyms_delete_candidates,
      gene_extract_features, 
      pheno_extract_candidates, 
      pheno_acronyms_extract_candidates,
      pheno_acronyms_aggregate_candidates,
      pheno_acronyms_insert_candidates,
      # pheno_extract_features,
      get_genepheno_pairs,
      serialize_genepheno_pairs_split,
      genepheno_extract_candidates,
      gene_filter_candidates,
      # pheno_filter_candidates,
      genepheno_extract_features,
      genepheno_causation_supervision,
      genepheno_association_supervision,
      gene_inference,
      # pheno_inference,
      genepheno_causation_to_gene,
      genepheno_association_to_gene,
      genepheno_association_inference,
      genepheno_causation_inference,
      # pheno_acronyms_inference
    ]
    canonicalize: [
      canonicalize_genepheno_causation,
      canonicalize_genepheno_association
    ]
    half_pipeline_gp: [
      get_genepheno_pairs,
      serialize_genepheno_pairs_split,
      genepheno_extract_candidates,
      genepheno_causation_supervision,
      genepheno_association_supervision,
      gene_inference,
      # pheno_inference,
      genepheno_causation_to_gene,
      genepheno_association_to_gene,
      genepheno_association_inference,
      genepheno_causation_inference,
    ]
    inference_gp: [
      gene_inference,
      pheno_inference,
      genepheno_causation_inference,
      genepheno_causation_to_gene,
      genepheno_causation_to_pheno
      genepheno_association_inference,
      genepheno_association_to_gene,
      genepheno_association_to_pheno
    ]
    postprocess: [
      extract_entity_level_relations
    ]
  }


### EXTRACTORS ###
  extraction.extractors {

    serialize_sentences: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS sentences_input CASCADE;
        CREATE TABLE 
          sentences_input
        AS (SELECT
          doc_id,
          section_id,
          sent_id,
          array_to_string(words, '|^|') AS words,
          array_to_string(lemmas, '|^|') AS lemmas,
          array_to_string(poses, '|^|') AS poses,
          array_to_string(ners, '|^|') AS ners,
          array_to_string(dep_paths, '|^|') AS dep_paths,
          array_to_string(dep_parents, '|^|') AS dep_parents
        FROM
          sentences) DISTRIBUTED BY (doc_id);
      """
    }

    cleanup_doc_ids1: {
      style: sql_extractor
      sql: """
        DELETE FROM doc_metadata
        WHERE (doc_id in (
          SELECT doc_id FROM doc_metadata WHERE issn_print <> 'null'
        )
        AND issn_print = 'null'
        );
        DELETE FROM doc_metadata
        WHERE (doc_id in (
          SELECT doc_id FROM doc_metadata WHERE issn_electronic <> 'null'
        )
        AND issn_electronic = 'null' AND issn_print = 'null'
        );
        DELETE FROM doc_metadata
        WHERE (doc_id in (
          SELECT doc_id FROM doc_metadata WHERE issn_global <> 'null'
        )
        AND issn_global = 'null' AND issn_print = 'null' AND issn_electronic = 'null'
        );
        DELETE FROM doc_metadata
        WHERE (doc_id in (
          SELECT doc_id FROM doc_metadata WHERE doc_id !~ '^[0-9]+' GROUP BY doc_id HAVING count(doc_id) >= 3
        )
        );
      """
    }

    cleanup_doc_ids2: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS doc_metadata_uniq CASCADE;
        ALTER TABLE doc_metadata RENAME TO doc_metadata_uniq;
        CREATE TABLE doc_metadata AS (SELECT * FROM doc_metadata_uniq LIMIT 1) DISTRUBTED BY (doc_id);
        TRUNCATE TABLE doc_metadata;
        INSERT INTO doc_metadata (SELECT DISTINCT ON (doc_id) * FROM doc_metadata_uniq);
      """
      dependencies: [cleanup_doc_ids1]
    }

    load_hg19_ensGene: {
      style: tsv_extractor
      before: ${APP_HOME}/util/load_hg19_ensGene.sh ${DBNAME} ${APP_HOME}/onto/raw/hg19_ensGene.sql
      input: """
        SELECT * FROM
          (SELECT 1 a, 2 b, 3 c) x
      """
      udf: /bin/cat
      output_relation: dummy
      parallelism: 1
    }

    load_allowed_phenos: {
      style: tsv_extractor
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} allowed_phenos
      input: """ SELECT 1 a, 2 b, 3 c """
      output_relation: allowed_phenos
      udf: ${APP_HOME}/code/create_allowed_phenos_list.py
      parallelism: 1
      after: ${APP_HOME}/util/uniq_table.sh ${DBNAME} allowed_phenos
    }

    load_genes: {
      style: tsv_extractor
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} genes
      input: """ SELECT 1 a, 2 b, 3 c """
      output_relation: genes
      udf: ${APP_HOME}/code/load_ensembl_table.sh
      parallelism: 1
      after: ${APP_HOME}/util/uniq_table.sh ${DBNAME} genes
    }

    load_ensembl_protein_sequences: {
      style: tsv_extractor
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} ensembl_protein_sequences
      input: """ SELECT 1 a, 2 b, 3 c """
      output_relation: ensembl_protein_sequences
      udf: /bin/cat ${APP_HOME}/onto/data/ucscEnsemblProteinTable.tsv
      parallelism: 1
      after: ${APP_HOME}/util/uniq_table.sh ${DBNAME} ensembl_protein_sequences
    }

    load_ensembl_gene_sequences: {
      style: tsv_extractor
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} ensembl_gene_sequences
      input: """ SELECT 1 a, 2 b, 3 c """
      output_relation: ensembl_gene_sequences
      udf: /bin/cat ${APP_HOME}/onto/data/ucscEnsemblGeneTable.tsv
      parallelism: 1
      after: ${APP_HOME}/util/uniq_table.sh ${DBNAME} ensembl_gene_sequences
    }

    load_genepheno_holdout_set: {
      style: tsv_extractor
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} genepheno_holdout_set
      input: """ SELECT 1 a, 2 b, 3 c"""
      output_relation: genepheno_holdout_set
      udf: cat ${APP_HOME}/onto/manual/genepheno_holdout_set.tsv
      parallelism: 1
      after: ${APP_HOME}/util/uniq_table.sh ${DBNAME} genepheno_holdout_set
    }

    all_gene_names_to_transcripts: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS gene_to_transcripts;
        CREATE TABLE gene_to_transcripts AS (
          SELECT DISTINCT
            g.gene_name,
            array_to_string(ARRAY_AGG(eg.name2), '|~|') ensembl_ids,
            array_to_string(ARRAY_AGG(eg.name), '|~|') ensembl_transcripts,
            array_to_string(ARRAY_AGG(eg.chrom), '|~|') chroms,
            array_to_string(ARRAY_AGG(eg.strand), '|~|') strands,
            array_to_string(ARRAY_AGG(eg.cdsstart), '|~|') txstarts,
            array_to_string(ARRAY_AGG(eg.cdsend), '|~|') txends,
            array_to_string(ARRAY_AGG(eg.exonstarts), '|~|') exonstarts,
            array_to_string(ARRAY_AGG(eg.exonends), '|~|') exonends
          FROM
            genes g
            JOIN ensgene eg
              ON (g.ensembl_id = eg.name2)
          GROUP BY
            gene_name
        );
      """
    }

    precision: {
      style: tsv_extractor
      input: """ SELECT 1 a, 2 b, 3 c"""
      output_relation: dummy
      udf: ${APP_HOME}/util/holdout_precision.sh ${DBNAME}
      parallelism: 1
      dependencies: [genepheno_association_inference, genepheno_causation_inference, load_genepheno_holdout_set, load_genepheno_holdout_labels]
    }

    load_genepheno_holdout_labels: {
      style: tsv_extractor
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} genepheno_holdout_labels
      input: """ SELECT 1 a, 2 b, 3 c"""
      output_relation: genepheno_holdout_labels
      udf: cat ${APP_HOME}/onto/manual/genepheno_holdout_labels.tsv
      parallelism: 1
      after: ${APP_HOME}/util/uniq_table.sh ${DBNAME} genepheno_holdout_labels
    }

    load_hpo_abnormalities: {
      style: tsv_extractor
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} hpo_abnormalities
      input: """ SELECT 1 a, 2 b , 3 c """
      output_relation: hpo_abnormalities
      udf: ${APP_HOME}/onto/load_hpo_abnormalities.py
      parallelism: 1
      after: ${APP_HOME}/util/uniq_table.sh ${DBNAME} hpo_abnormalities
    }

    load_charite_canon: {
      style: tsv_extractor
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} charite_canon
      input: """ SELECT 1 a, 2 b, 3 c """
      output_relation: charite_canon
      udf: cat ${APP_HOME}/onto/data/canon_phenotype_to_ensgene.map
      parallelism: 1
      after: ${APP_HOME}/util/uniq_table.sh ${DBNAME} charite_canon
    }

    load_hgvs_hpo: {
      style: tsv_extractor
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} hgvs_hpo
      input: """ SELECT 1 a, 2 b, 3 c """
      output_relation: hgvs_hpo
      udf: cat ${APP_HOME}/onto/data/hgvs_to_hpo.tsv
      parallelism: 1
      after: ${APP_HOME}/util/uniq_table.sh ${DBNAME} hgvs_hpo
    }

    load_charite: {
      style: tsv_extractor
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} charite
      input: """ SELECT 1 a, 2 b, 3 c """
      output_relation: charite
      udf: cat ${APP_HOME}/onto/manual/harendra_phenotype_to_gene.map
      parallelism: 1
      after: ${APP_HOME}/util/uniq_table.sh ${DBNAME} charite_canon
    }

    gene_extract_candidates: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} gene_mentions
      style: tsv_extractor
      # TODO after variants, insert variants next to pheno_mentions!!
      input: """
        SELECT
          si.doc_id,
          si.section_id,
          si.sent_id,
          si.words,
          si.dep_paths,
          si.dep_parents,
          si.lemmas,
          si.poses,
          si.ners
        FROM 
          sentences_input si
          JOIN 
          (SELECT DISTINCT doc_id FROM pheno_mentions) os
            ON (si.doc_id = os.doc_id)
      """
      output_relation: gene_mentions
      udf: ${APP_HOME}/code/gene_extract_candidates.py
      parallelism: ${PARALLELISM}
      dependencies: [serialize_sentences, load_genes, cleanup_doc_ids2, pheno_extract_candidates, pheno_acronyms_insert_candidates]
    }

    non_gene_acronyms_delete_candidates: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS gene_mentions_non_gene_acronyms;
        CREATE TABLE gene_mentions_non_gene_acronyms AS
        (SELECT * FROM gene_mentions gm
        WHERE (gm.gene_name) IN
          (SELECT abbrev
           FROM non_gene_acronyms nga
           WHERE (is_correct = 't' OR is_correct is null)
             AND nga.doc_id = gm.doc_id)) DISTRIBUTED BY (doc_id);
        DELETE FROM gene_mentions gm
        WHERE (gm.gene_name) IN
          (SELECT abbrev
           FROM non_gene_acronyms nga
           WHERE (is_correct = 't' OR is_correct is null)
             AND nga.doc_id = gm.doc_id);
      """
      dependencies: [gene_extract_candidates, non_gene_acronyms_extract_candidates]
    }

    gene_extract_features: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} gene_features
      style: tsv_extractor
      input: """
        SELECT
          s.doc_id,
          s.section_id,
          s.sent_id,
          s.words,
          s.lemmas,
          s.poses,
          s.ners,
          s.dep_paths,
          s.dep_parents,
          m.mention_id,
          m.supertype,
          m.wordidxs
        FROM 
          gene_mentions_filtered m
          JOIN 
          sentences_input_with_gene_mention s
            ON (s.doc_id = m.doc_id AND s.section_id = m.section_id AND s.sent_id = m.sent_id)
      """
      output_relation: gene_features
      udf: ${APP_HOME}/code/gene_extract_features.py
      parallelism: ${PARALLELISM}
      dependencies: [gene_extract_candidates, cleanup_doc_ids2, non_gene_acronyms_delete_candidates, gene_filter_candidates]
    }

    variant_extract_candidates: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} variant_mentions
      style: tsv_extractor
      input: """
        SELECT
          doc_id,
          section_id,
          sent_id,
          words
        FROM 
          sentences_input
      """
      output_relation: variant_mentions
      udf: ${APP_HOME}/code/variant_extract_candidates.py
      parallelism: ${PARALLELISM}
    }

    pheno_extract_candidates: {
      before: ${APP_HOME}/util/pheno_extract_candidates_before.sh
      style: tsv_extractor
      input: """
        SELECT 
          doc_id,
          section_id,
          sent_id,
          words,
          lemmas,
          poses,
          ners
        FROM 
          sentences_input
      """
      output_relation: pheno_mentions
      udf: ${APP_HOME}/code/pheno_extract_candidates.py
      parallelism: ${PARALLELISM}
      input_batch_size: 100000
      dependencies: [serialize_sentences, cleanup_doc_ids2]
    }

    variant_extract_features: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} variant_features
      style: tsv_extractor
      input: """
        SELECT 
          s.doc_id,
          s.section_id,
          s.sent_id,
          s.words,
          s.lemmas,
          s.poses,
          s.ners,
          s.dep_paths,
          s.dep_parents,
          m.mention_id,
          array_to_string(m.wordidxs, '|^|')
        FROM 
          sentences_input s
          JOIN variant_mentions_filtered m
            ON (s.doc_id = m.doc_id AND s.section_id = m.section_id AND s.sent_id = m.sent_id)
      """
      output_relation: variant_features
      udf: ${APP_HOME}/code/variant_extract_features.py
      parallelism: ${PARALLELISM}
      dependencies: [variant_extract_candidates, cleanup_doc_ids2]
    }

    pheno_extract_features: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} pheno_features
      style: tsv_extractor
      input: """
        SELECT
          s.doc_id,
          s.section_id,
          s.sent_id,
          s.words,
          s.lemmas,
          s.poses,
          s.ners,
          s.dep_paths,
          s.dep_parents,
          m.mention_id,
          array_to_string(m.wordidxs, '|^|')
        FROM 
          sentences_input_with_pheno_mention s
          JOIN pheno_mentions_filtered m
            ON (s.doc_id = m.doc_id AND s.section_id = m.section_id AND s.sent_id = m.sent_id)
      """
      output_relation: pheno_features
      udf: ${APP_HOME}/code/pheno_extract_features.py
      parallelism: ${PARALLELISM}
      dependencies: [pheno_extract_candidates, pheno_acronyms_insert_candidates, cleanup_doc_ids2, pheno_filter_candidates]
    }
  
    # We first get G-P pairs, then aggregate & serialize them, then do G-P supervision
    # This is to avoide the VMEM error caused by large operations
    # This is also in line with what we will do when we switch to ddlog format
    get_genepheno_pairs: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS genepheno_pairs;
        CREATE TABLE genepheno_pairs AS (
          SELECT
            g.doc_id,
            g.section_id,
            g.sent_id,
            g.mention_id AS gene_mention_id,
            g.gene_name AS gene_name,
            array_to_string(g.wordidxs, '|~|') AS gene_wordidxs,
            g.is_correct AS gene_is_correct,
            p.mention_id AS pheno_mention_id,
            p.entity AS pheno_entity,
            array_to_string(p.wordidxs, '|~|') AS pheno_wordidxs,
            p.is_correct AS pheno_is_correct
          FROM
            gene_mentions g
            JOIN pheno_mentions p
              ON (g.doc_id = p.doc_id AND g.section_id = p.section_id AND g.sent_id = p.sent_id)
        ) DISTRIBUTED BY (doc_id);
      """
      dependencies: [non_gene_acronyms_delete_candidates, gene_extract_candidates, pheno_acronyms_insert_candidates, cleanup_doc_ids2]
    }

    serialize_genepheno_pairs_split: {
      style: tsv_extractor
      after: ${APP_HOME}/util/serialize_genepheno_pairs_split.sh ${DBNAME}
      input: """
        SELECT * FROM
          (SELECT 1 a, 2 b, 3 c) x
      """
      udf: /bin/cat
      output_relation: dummy
      dependencies: [get_genepheno_pairs, cleanup_doc_ids2]
      parallelism: 1
    }

    get_genevariant_pairs: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS genevariant_pairs;
        CREATE TABLE genevariant_pairs AS (
          SELECT
            g.doc_id doc_id,
            g.section_id gene_section_id,
            g.sent_id gene_sent_id,
            v.section_id variant_section_id,
            v.sent_id variant_sent_id,
            g.mention_id AS gene_mention_id,
            g.gene_name AS gene_name,
            array_to_string(g.wordidxs, '|^|') AS gene_wordidxs,
            g.is_correct AS gene_is_correct,
            v.mention_id AS variant_mention_id,
            v.entity AS variant_entity,
            array_to_string(v.wordidxs, '|^|') AS variant_wordidxs,
            v.variant_type,
            v.ivsnum variant_ivsnum,
            v.pos variant_pos,
            v.posplus variant_posplus,
            v.frompos variant_frompos,
            v.topos variant_topos,
            v.seq variant_seq,
            v.fromseq variant_fromseq,
            v.toseq variant_toseq,
            v.is_correct AS variant_is_correct
          FROM
            gene_mentions g
            JOIN variant_mentions v
              ON (g.doc_id = v.doc_id)
        ) DISTRIBUTED BY (doc_id);
      """
      dependencies: [non_gene_acronyms_delete_candidates, gene_extract_candidates, variant_extract_candidates, cleanup_doc_ids2]
    }

    non_gene_acronyms_extract_candidates: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} non_gene_acronyms
      style: tsv_extractor
      input: """
        SELECT
          a.doc_id,
          a.section_id,
          a.sent_id,
          a.word_string,
          a.dep_paths,
          a.dep_parents,
          a.lemmas,
          a.poses,
          a.ners,
          a.wordidx
        FROM
         (SELECT
            si.doc_id,
            si.section_id,
            si.sent_id,
            si.words as word_string,
            string_to_array(si.words, '|^|') words,
            si.dep_paths,
            si.dep_parents,
            si.lemmas,
            si.poses,
            si.ners,
            gm.wordidxs[1] as wordidx
          FROM
            sentences_input si
          JOIN (SELECT DISTINCT doc_id, section_id, sent_id, wordidxs FROM gene_mentions) gm
            ON (si.doc_id = gm.doc_id AND si.section_id = gm.section_id AND si.sent_id = gm.sent_id)
          WHERE
            si.words LIKE '%-LRB-%'
        ) a
        WHERE
          a.words[a.wordidx] LIKE '-LRB-';
      """
      output_relation: non_gene_acronyms
      udf: ${APP_HOME}/code/non_gene_acronyms_extract_candidates.py
      parallelism: ${PARALLELISM}
      dependencies: [serialize_sentences, load_genes, gene_extract_candidates, cleanup_doc_ids2]
    }

    non_gene_acronyms_extract_features: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} non_gene_acronyms_features
      style: tsv_extractor
      input: """
        SELECT 
          s.doc_id,
          s.section_id,
          s.sent_id,
          s.words,
          s.lemmas,
          s.poses,
          s.ners,
          s.dep_paths,
          s.dep_parents,
          m.mention_id,
          m.supertype,
          array_to_string(m.short_wordidxs, '|^|'),
          array_to_string(m.long_wordidxs, '|^|')
        FROM 
          sentences_input s
          JOIN non_gene_acronyms m
            ON (s.doc_id = m.doc_id AND s.section_id = m.section_id AND s.sent_id = m.sent_id)
      """
      output_relation: non_gene_acronyms_features
      udf: ${APP_HOME}/code/non_gene_acronyms_extract_features.py
      parallelism: ${PARALLELISM}
      dependencies: [non_gene_acronyms_extract_candidates, cleanup_doc_ids2]
    }

    pheno_acronyms_extract_candidates: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} pheno_acronyms
      style: tsv_extractor
      input: """
        SELECT
          a.doc_id,
          a.section_id,
          a.sent_id,
          a.word_string,
          a.dep_paths,
          a.dep_parents,
          a.lemmas,
          a.poses,
          a.ners,
          a.wordidxs,
          a.entity
        FROM
         (SELECT
            si.doc_id,
            si.section_id,
            si.sent_id,
            si.words as word_string,
            string_to_array(si.words, '|^|') words,
            si.dep_paths,
            si.dep_parents,
            si.lemmas,
            si.poses,
            si.ners,
            pm.wordidxs,
            pm.entity
          FROM
            sentences_input si
          JOIN (SELECT DISTINCT doc_id, section_id, sent_id, wordidxs, entity FROM pheno_mentions WHERE is_correct = 't' OR is_correct is null) pm
            ON (si.doc_id = pm.doc_id AND si.section_id = pm.section_id AND si.sent_id = pm.sent_id)
          WHERE
            si.words LIKE '%-LRB-%'
        ) a
        WHERE
          a.words[a.wordidxs[array_upper(a.wordidxs, 1)]+2] LIKE '-LRB-';
      """
      output_relation: pheno_acronyms
      udf: ${APP_HOME}/code/pheno_acronyms_extract_candidates.py
      parallelism: ${PARALLELISM}
      dependencies: [serialize_sentences, load_hpo_abnormalities, pheno_extract_candidates, cleanup_doc_ids2]
    }

    pheno_acronyms_aggregate_candidates: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS pheno_acronyms_aggregate;
        CREATE TABLE pheno_acronyms_aggregate AS (
          SELECT DISTINCT
            doc_id,
            array_to_string(ARRAY_AGG(section_id), '|^|') pa_section_ids,
            array_to_string(ARRAY_AGG(sent_id), '|^|') pa_sent_ids,
            array_to_string(ARRAY_AGG(abbrev), '|^|') pa_abbrevs,
            array_to_string(ARRAY_AGG(entity), '|^|') pheno_entities
          FROM
            pheno_acronyms
          WHERE
            is_correct = 't'
          GROUP BY
            doc_id
        ) DISTRIBUTED BY (doc_id);
        DROP TABLE IF EXISTS pheno_acronyms_ids;
        CREATE TABLE pheno_acronyms_ids AS ( 
          SELECT DISTINCT doc_id FROM pheno_acronyms_aggregate
        ) DISTRIBUTED BY (doc_id);
        DROP TABLE IF EXISTS sentences_input_with_pheno_acronyms;
        CREATE TABLE sentences_input_with_pheno_acronyms AS ( 
          SELECT 
            si.* 
          FROM 
            sentences_input si
            JOIN pheno_acronyms_ids pa
              ON (si.doc_id = pa.doc_id)
        ) DISTRIBUTED BY (doc_id);
      """
      dependencies: [pheno_acronyms_extractor_candidates]
    }

    pheno_acronyms_insert_candidates: {
      style: tsv_extractor
      input: """
        SELECT
          si.doc_id,
          si.section_id,
          si.sent_id,
          si.words,
          si.lemmas,
          si.poses,
          si.ners,
          pa_abbrevs,
          pheno_entities,
          pa_section_ids,
          pa_sent_ids
        FROM
          sentences_input_with_pheno_acronyms si
          JOIN pheno_acronyms_aggregate pa
            ON (si.doc_id = pa.doc_id)
      """
      output_relation: pheno_mentions
      udf: ${APP_HOME}/code/pheno_acronyms_to_mentions.py
      parallelism: ${PARALLELISM}
      dependencies: [pheno_acronyms_extract_candidates, pheno_extract_candidates, pheno_acronyms_aggregate_candidates]
    }

    pheno_acronyms_extract_features: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} pheno_acronyms_features
      style: tsv_extractor
      input: """
        SELECT 
          s.doc_id,
          s.section_id,
          s.sent_id,
          s.words,
          s.lemmas,
          s.poses,
          s.ners,
          s.dep_paths,
          s.dep_parents,
          m.mention_id,
          m.supertype,
          array_to_string(m.short_wordidxs, '|^|'),
          array_to_string(m.long_wordidxs, '|^|')
        FROM 
          sentences_input s
          JOIN pheno_acronyms m
            ON (s.doc_id = m.doc_id AND s.section_id = m.section_id AND s.sent_id = m.sent_id)
      """
      output_relation: pheno_acronyms_features
      udf: ${APP_HOME}/code/pheno_acronyms_extract_features.py
      parallelism: ${PARALLELISM}
      dependencies: [pheno_acronyms_extract_candidates, cleanup_doc_ids2]
    }
    
    genepheno_extract_candidates: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} genepheno_relations
      style: tsv_extractor
      input: """
        SELECT
          s.doc_id,
          s.section_id,
          s.sent_id,
          s.words,
          s.lemmas,
          s.poses,
          s.dep_paths,
          s.dep_parents,
          gp.gene_mention_ids AS gene_mention_ids,
          gp.gene_names AS gene_names,
          gp.gene_wordidxs AS gene_wordidxs,
          gp.gene_is_corrects AS gene_is_corrects,
          gp.pheno_mention_ids AS pheno_mention_ids,
          gp.pheno_entities AS pheno_entities,
          gp.pheno_wordidxs AS pheno_wordidxs,
          gp.pheno_is_corrects AS pheno_is_corrects
        FROM
          sentences_input s
          JOIN genepheno_pairs_sentences gp
            ON (s.doc_id = gp.doc_id AND s.section_id = gp.section_id AND s.sent_id = gp.sent_id)
        """
      output_relation: genepheno_relations
      udf: ${APP_HOME}/code/genepheno_extract_candidates.py
      parallelism: ${PARALLELISM}
      dependencies: [serialize_genepheno_pairs_split, cleanup_doc_ids2]
    }

    genevariant_extract_candidates: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} genevariant_relations
      style: tsv_extractor
      input: """
        SELECT
          doc_id,
          variant_section_id,
          variant_sent_id,
          variant_entity,
          variant_wordidxs,
          variant_type,
          variant_ivsnum,
          variant_pos,
          variant_posplus,
          variant_frompos,
          variant_topos,
          variant_seq,
          variant_fromseq,
          variant_toseq,
          variant_is_correct,
          array_to_string(ARRAY_AGG(gene_section_id), '|^|') gene_section_ids,
          array_to_string(ARRAY_AGG(gene_sent_id), '|^|') gene_sent_ids,
          array_to_string(ARRAY_AGG(gene_wordidxs), '|^|') gene_wordidxs,
          array_to_string(ARRAY_AGG(gt.gene_name), '|^|') gene_names,
          array_to_string(ARRAY_AGG(gene_is_correct), '|^|') gene_is_corrects,
          array_to_string(ARRAY_AGG(ensembl_ids), '|^|') ensembl_ids,
          array_to_string(ARRAY_AGG(ensembl_transcripts), '|^|') ensembl_transcripts,
          array_to_string(ARRAY_AGG(chroms), '|^|') chroms,
          array_to_string(ARRAY_AGG(strands), '|^|') strands,
          array_to_string(ARRAY_AGG(txstarts), '|^|') txstarts,
          array_to_string(ARRAY_AGG(txends), '|^|') txends,
          array_to_string(ARRAY_AGG(exonstarts), '|^|') exonstarts,
          array_to_string(ARRAY_AGG(exonends), '|^|') exonends
        FROM
          genevariant_pairs gv
          JOIN gene_to_transcripts gt
            ON (gv.gene_name = gt.gene_name)
        GROUP BY
          doc_id,
          variant_section_id,
          variant_sent_id,
          variant_entity,
          variant_wordidxs,
          variant_type,
          variant_ivsnum,
          variant_pos,
          variant_posplus,
          variant_frompos,
          variant_topos,
          variant_seq,
          variant_fromseq,
          variant_toseq,
          variant_is_correct
        """
      output_relation: genevariant_relations
      udf: ${APP_HOME}/code/genevariant_extract_candidates.py
      parallelism: ${PARALLELISM}
      dependencies: [serialize_genevariant_pairs_split, cleanup_doc_ids2]
    }

    genevariant_supervise_matching_coding_genes: {
      style: sql_extractor
      sql: """
        -- supervise true: (into genevariant_supervise_true; stuff where multiple genes in doc, but only one matches variant):
        CREATE TABLE genevariant_coding_supervise_true AS (
        SELECT DISTINCT
          vm.doc_id,
          vm.mention_id,
          vm.entity,
          vm.pos,
          fromseq,
          toseq,
          ARRAY_AGG(DISTINCT g.gene_name) gene_names 
        FROM
          variant_mentions vm 
          JOIN gene_mentions gm 
            ON (vm.doc_id = gm.doc_id) 
          JOIN genes g 
            ON (gm.gene_name = g.gene_name) 
          JOIN ensgene eg 
            ON (g.ensembl_id = eg.name2) 
          JOIN ensembl_gene_sequences eps 
            ON (eg.name = eps.ensembl_transcript) 
        WHERE
          vm.pos IS NOT NULL 
          AND fromseq IS NOT NULL 
          AND vm.variant_type LIKE 'coding%' 
          AND fromseq != 'U'
          AND fromseq = n_seq[vm.pos::int] 
          AND posplus IS NULL
        GROUP BY
          vm.doc_id, 
          vm.entity, 
          vm.mention_id,
          vm.pos, 
          fromseq, 
          toseq 
        HAVING
          ARRAY_LENGTH(ARRAY_AGG(DISTINCT g.gene_name), 1) = 1
        ORDER BY
          doc_id, entity);
        -- supervise false: (stuff where multiple genes in the doc, but only one matches above)
        CREATE TABLE genevariant_coding_supervise_false AS (SELECT
          gv.doc_id, 
          gv.variant_entity, 
          gv.variant_mention_id, 
          gv.variant_pos, 
          gv.variant_fromseq, 
          gv.variant_toseq, 
          gv.gene_name 
        FROM 
          genevariant_pairs gv 
          JOIN genevariant_supervise_true gst 
            ON (gv.variant_mention_id = gst.mention_id) 
        WHERE gv.gene_name != gst.gene_names);
      """
      dependencies: [genevariant_extract_candidates, load_ensembl_gene_sequences]
    }

    genevariant_supervise_matching_proteins: {
      style: sql_extractor
      sql: """
        -- supervise true: (into genevariant_supervise_true; stuff where multiple genes in doc, but only one matches variant):
        CREATE TABLE genevariant_protein_supervise_true AS (
        SELECT DISTINCT
          vm.doc_id,
          vm.mention_id,
          vm.entity,
          vm.pos,
          fromseq,
          toseq,
          ARRAY_AGG(DISTINCT g.gene_name) gene_names 
        FROM
          variant_mentions vm 
          JOIN gene_mentions gm 
            ON (vm.doc_id = gm.doc_id) 
          JOIN genes g 
            ON (gm.gene_name = g.gene_name) 
          JOIN ensgene eg 
            ON (g.ensembl_id = eg.name2) 
          JOIN ensembl_protein_sequences eps 
            ON (eg.name = eps.ensembl_transcript) 
        WHERE
          vm.pos IS NOT NULL 
          AND fromseq IS NOT NULL 
          AND vm.variant_type LIKE 'protein%' 
          AND fromseq != 'U'
          AND fromseq = aa_seq[vm.pos::int] 
          AND posplus IS NULL
        GROUP BY
          vm.doc_id, 
          vm.mention_id,
          vm.entity, 
          vm.pos, 
          fromseq, 
          toseq 
        HAVING
          ARRAY_LENGTH(ARRAY_AGG(DISTINCT g.gene_name), 1) = 1
        ORDER BY
          doc_id, entity);
        -- supervise false: (stuff where multiple genes in the doc, but only one matches above)
        CREATE TABLE genevariant_protein_supervise_false AS (SELECT
          gv.doc_id, 
          gv.variant_entity, 
          gv.variant_mention_id, 
          gv.variant_pos, 
          gv.variant_fromseq, 
          gv.variant_toseq, 
          gv.gene_name 
        FROM 
          genevariant_pairs gv 
          JOIN genevariant_supervise_true gst 
            ON (gv.variant_mention_id = gst.mention_id) 
        WHERE gv.gene_name != gst.gene_names);
      """
      dependencies: [genevariant_extract_candidates, load_ensembl_protein_sequences]
    }
    
    # Filter candidates that we perform inference on
    gene_filter_candidates: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS gene_mentions_filtered CASCADE;
        CREATE TABLE gene_mentions_filtered AS (
          SELECT DISTINCT
            g.id,
            g.doc_id,
            g.section_id,
            g.sent_id,
            array_to_string(g.wordidxs, '|^|') wordidxs,
            g.mention_id,
            g.mapping_type,
            g.supertype,
            g.subtype,
            g.gene_name,
            array_to_string(g.words, '|^|') words,
            g.is_correct
          FROM
            gene_mentions g
            JOIN genepheno_relations gp
              ON (g.mention_id = gp.gene_mention_id)
        ) DISTRIBUTED BY (doc_id);
        DROP TABLE IF EXISTS gene_mention_ids;
        CREATE TABLE gene_mention_ids AS (
          SELECT DISTINCT doc_id FROM gene_mentions_filtered
        ) DISTRIBUTED BY (doc_id);
        DROP TABLE IF EXISTS sentences_input_with_gene_mention;
        CREATE TABLE sentences_input_with_gene_mention AS (
          SELECT 
            si.*
          FROM
            sentences_input si
            JOIN gene_mention_ids gm
              ON (si.doc_id = gm.doc_id)
        ) DISTRIBUTED BY (doc_id);
      """
      dependencies: [genepheno_extract_candidates]
    }

    variant_filter_candidates: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS variant_mentions_filtered CASCADE;
        CREATE TABLE variant_mentions_filtered AS (
          SELECT DISTINCT
            v.*
          FROM
            variant_mentions v
            JOIN genevariant_relations gv
              ON (v.mention_id = gv.variant_mention_id)
        ) DISTRIBUTED BY (doc_id);
      """
      dependencies: [genevariant_extract_candidates]
    }

    pheno_filter_candidates: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS pheno_mentions_filtered CASCADE;
        CREATE TABLE pheno_mentions_filtered AS (
          SELECT DISTINCT
            p.*
            g.id,
            g.doc_id,
            g.section_id,
            g.sent_id,
            array_to_string(g.wordidxs, '|^|') wordidxs,
            g.mention_id,
            g.mapping_type,
            g.supertype,
            g.subtype,
            g.gene_name,
            array_to_string(g.words, '|^|') words,
            g.is_correct
          FROM
            pheno_mentions p
            JOIN genepheno_relations gp
              ON (p.mention_id = gp.pheno_mention_id)
          ) DISTRIBUTED BY (doc_id);
        DROP TABLE IF EXISTS pheno_mention_ids;
        CREATE TABLE pheno_mention_ids AS (
          SELECT DISTINCT doc_id FROM pheno_mentions_filtered
        ) DISTRIBUTED BY (doc_id);
        DROP TABLE IF EXISTS sentences_input_with_pheno_mention;
        CREATE TABLE sentences_input_with_pheno_mention AS (
          SELECT 
            si.*
          FROM
            sentences_input si
            JOIN pheno_mention_ids gm
              ON (si.doc_id = gm.doc_id)
        ) DISTRIBUTED BY (doc_id);
      """
      dependencies: [genepheno_extract_candidates]
    }
    
    genepheno_extract_features: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} genepheno_features
      style: tsv_extractor
      input: """SELECT
              r.relation_id,
              r.doc_id,
              r.section_id,
              r.sent_id,
              r.gene_mention_id,
              r.gene_wordidxs,
              r.pheno_mention_id,
              r.pheno_wordidxs,
              s.words,
              s.lemmas,
              s.poses,
              s.ners,
              s.dep_paths,
              s.dep_parents
           FROM
              genepheno_relations r
              JOIN sentences_input s
                ON (r.doc_id = s.doc_id AND r.section_id = s.section_id AND r.sent_id = s.sent_id)
        """
      output_relation: genepheno_features
      udf: ${APP_HOME}/code/genepheno_extract_features.py
      parallelism: ${PARALLELISM}
      dependencies: [genepheno_extract_candidates]
    }

    genepheno_association_supervision: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} genepheno_association
      style: tsv_extractor
      input: """SELECT 
        r.relation_id,
        r.doc_id,
        r.section_id,
        r.sent_id,
        r.gene_mention_id,
        r.gene_name,
        r.gene_wordidxs,
        r.gene_is_correct,
        r.pheno_mention_id,
        r.pheno_entity,
        r.pheno_wordidxs,
        r.pheno_is_correct,
        s.words,
        s.lemmas,
        s.poses,
        s.dep_paths,
        s.dep_parents
      FROM 
        genepheno_relations r
        join sentences_input s on (r.doc_id = s.doc_id AND r.section_id = s.section_id AND r.sent_id = s.sent_id)
      """
      output_relation: genepheno_association
      udf: ${APP_HOME}/code/genepheno_association_supervision.py
      parallelism: ${PARALLELISM}
      dependencies: [genepheno_extract_candidates]
    }

    genepheno_causation_supervision: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} genepheno_causation
      style: tsv_extractor
      input: """SELECT 
        r.relation_id,
        r.doc_id,
        r.section_id,
        r.sent_id,
        r.gene_mention_id,
        r.gene_name,
        r.gene_wordidxs,
        r.gene_is_correct,
        r.pheno_mention_id,
        r.pheno_entity,
        r.pheno_wordidxs,
        r.pheno_is_correct,
        s.words,
        s.lemmas,
        s.poses,
        s.dep_paths,
        s.dep_parents
      FROM 
        genepheno_relations r
        join sentences_input s on (r.doc_id = s.doc_id AND r.section_id = s.section_id AND r.sent_id = s.sent_id)
      """
      output_relation: genepheno_causation
      udf: ${APP_HOME}/code/genepheno_causation_supervision.py
      parallelism: ${PARALLELISM}
      dependencies: [genepheno_extract_candidates]
    }

    extract_entity_level_relations: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS genepheno_entity_level;
        CREATE TABLE genepheno_entity_level AS (
          SELECT
            gpa.gene_name AS gene_name,
            gpa.pheno_entity AS pheno_entity,
            ARRAY_AGG(gpa.relation_id) AS relation_ids,
            ARRAY_AGG(gpa.doc_id) AS doc_ids,
            ARRAY_AGG(gpa.section_id) AS section_ids,
            ARRAY_AGG(gpa.sent_id) AS sent_ids,
            ARRAY_AGG(array_to_string(gpa.gene_wordidxs, '|^|')) AS gene_wordidxs,
            ARRAY_AGG(array_to_string(gpa.pheno_wordidxs, '|^|')) AS pheno_wordidxs,
            ARRAY_AGG(si.words) AS words,
            ARRAY_AGG(gpa.expectation) AS a_expectations,
            ARRAY_AGG(gpc.expectation) AS c_expectations,
            MAX(gpa.expectation) AS max_a_expectation,
            MAX(gpc.expectation) AS max_c_expectation
          FROM
            genepheno_association_is_correct_inference gpa,
            genepheno_causation_is_correct_inference gpc,
            sentences_input si
          WHERE
            gpa.relation_id = gpc.relation_id
            AND gpa.doc_id = si.doc_id AND gpa.section_id = si.section_id AND gpa.sent_id = si.sent_id
            AND (gpa.expectation > 0.5 OR gpc.expectation > 0.5)
          GROUP BY
            gpa.gene_name, gpa.pheno_entity
        );
      """
    }

    canonicalize_genepheno_causation: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} genepheno_causation_canon
      style: tsv_extractor
      input: """SELECT DISTINCT
                  gm.pheno_entity,
                  g.ensembl_id
                FROM
                  genepheno_causation_is_correct_inference gm
                  JOIN genes g
                    ON (gm.gene_name = g.gene_name)
                WHERE
                  gm.expectation > 0.9;
             """
      output_relation: genepheno_causation_canon
      udf: ${APP_HOME}/onto/canonicalize_gene_phenotype.py /dev/stdin
      after: ${APP_HOME}/util/uniq_table.sh ${DBNAME} genepheno_causation_canon
      dependencies: [genepheno_causation_inference]
    }

    canonicalize_genepheno_association: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} genepheno_association_canon
      style: tsv_extractor
      input: """SELECT DISTINCT
                  gm.pheno_entity,
                  g.ensembl_id
                FROM
                  genepheno_association_is_correct_inference gm
                  JOIN genes g
                    ON (gm.gene_name = g.gene_name)
                WHERE
                  gm.expectation > 0.9;
             """
      output_relation: genepheno_association_canon
      udf: ${APP_HOME}/onto/canonicalize_gene_phenotype.py /dev/stdin
      after: ${APP_HOME}/util/uniq_table.sh ${DBNAME} genepheno_association_canon
      dependencies: [genepheno_association_inference]
    }

  }


  ### SCHEMA ###

  # Random variables
  schema.variables {
    gene_mentions_filtered.is_correct: Boolean
    pheno_mentions_filtered.is_correct: Boolean
    genepheno_association.is_correct: Boolean
    genepheno_causation.is_correct: Boolean
    non_gene_acronyms.is_correct: Boolean
    genevariant_relations.is_correct: Boolean
  }


### INFERENCE RULES ###

  # Inference rules
  inference.factors {
    gene_inference {
      input_query = """
        SELECT 
          gm.id as "gene_mentions_filtered.id",
          gm.is_correct as "gene_mentions_filtered.is_correct",
          gf.feature as "gene_features.feature"
        FROM
          gene_mentions_filtered gm,
          gene_features gf
        WHERE 
          gm.mention_id = gf.mention_id;
      """
      function: IsTrue(gene_mentions_filtered.is_correct)
      weight: "?(gene_features.feature)"
    }

    pheno_inference {
      input_query = """
        SELECT 
          pm.id as "pheno_mentions_filtered.id",
          pm.is_correct as "pheno_mentions_filtered.is_correct",
          pf.feature as "pheno_features.feature"
        FROM 
          pheno_mentions_filtered pm, 
          pheno_features pf
        WHERE 
          pm.mention_id = pf.mention_id;
      """
      function: IsTrue(pheno_mentions_filtered.is_correct)
      weight: "?(pheno_features.feature)"
    }

    variant_inference {
      input_query = """
        SELECT 
          vm.id as "variant_mentions_filtered.id",
          vm.is_correct as "variant_mentions_filtered.is_correct",
          vf.feature as "variant_features.feature"
        FROM 
          variant_mentions_filtered vm, 
          variant_features vf
        WHERE 
          vm.mention_id = vf.mention_id;
      """
      function: IsTrue(variant_mentions_filtered.is_correct)
      weight: "?(variant_features.feature)"
    }

    non_gene_acronyms_inference {
      input_query = """
        SELECT
          nga.id as "non_gene_acronyms.id",
          nga.is_correct as "non_gene_acronyms.is_correct",
          ngaf.feature as "non_gene_acronyms_features.feature"
        FROM
          non_gene_acronyms nga,
          non_gene_acronyms_features ngaf 
        WHERE nga.mention_id = ngaf.mention_id;
      """
      function: IsTrue(non_gene_acronyms.is_correct)
      weight: "?(non_gene_acronyms_features.feature)"
    }

    genepheno_association_inference {
      input_query = """
        SELECT 
          gpr.id as "genepheno_association.id",
          gpr.is_correct as "genepheno_association.is_correct",
          gpf.feature as "genepheno_features.feature"
        FROM 
          genepheno_association gpr,
          genepheno_features gpf
        WHERE 
          gpr.relation_id = gpf.relation_id;
      """
      function: IsTrue(genepheno_association.is_correct)
      weight: "?(genepheno_features.feature)"
    }

    genepheno_causation_inference {
      input_query = """
        SELECT 
          gpr.id as "genepheno_causation.id",
          gpr.is_correct as "genepheno_causation.is_correct",
          gpf.feature as "genepheno_features.feature"
        FROM 
          genepheno_causation gpr,
          genepheno_features gpf
        WHERE 
          gpr.relation_id = gpf.relation_id;
      """
      function: IsTrue(genepheno_causation.is_correct)
      weight: "?(genepheno_features.feature)"
    }

    genepheno_association_to_gene {
      input_query: """
        SELECT
          gp.id as "genepheno_association.id",
          gp.is_correct as "genepheno_association.is_correct",
          gm.id as "gene_mentions_filtered.id",
          gm.is_correct as "gene_mentions_filtered.is_correct"
        FROM
          genepheno_association gp,
          gene_mentions_filtered gm
        WHERE
          gp.doc_id = gm.doc_id
          AND gp.section_id = gm.section_id
          AND gp.gene_mention_id = gm.mention_id
        """
      function: "Imply(genepheno_association.is_correct, gene_mentions_filtered.is_correct)"
      weight: "?"
    }

    genepheno_association_to_pheno {
      input_query: """
        SELECT
          gp.id as "genepheno_association.id",
          gp.is_correct as "genepheno_association.is_correct",
          pm.id as "pheno_mentions_filtered.id",
          pm.is_correct as "pheno_mentions_filtered.is_correct"
        FROM
          genepheno_association gp,
          pheno_mentions_filtered pm
        WHERE
          gp.doc_id = pm.doc_id
          AND gp.section_id = pm.section_id
          AND gp.pheno_mention_id = pm.mention_id
        """
      function: "Imply(genepheno_association.is_correct, pheno_mentions_filtered.is_correct)"
      weight: "?"
    }

    genepheno_causation_to_gene {
      input_query: """
        SELECT
          gp.id as "genepheno_causation.id",
          gp.is_correct as "genepheno_causation.is_correct",
          gm.id as "gene_mentions_filtered.id",
          gm.is_correct as "gene_mentions_filtered.is_correct"
        FROM
          genepheno_causation gp,
          gene_mentions_filtered gm
        WHERE
          gp.doc_id = gm.doc_id
          AND gp.section_id = gm.section_id
          AND gp.gene_mention_id = gm.mention_id
        """
      function: "Imply(genepheno_causation.is_correct, gene_mentions_filtered.is_correct)"
      weight: "?"
    }

    genepheno_causation_to_pheno {
      input_query: """
        SELECT
          gp.id as "genepheno_causation.id",
          gp.is_correct as "genepheno_causation.is_correct",
          pm.id as "pheno_mentions_filtered.id",
          pm.is_correct as "pheno_mentions_filtered.is_correct"
        FROM
          genepheno_causation gp,
          pheno_mentions_filtered pm
        WHERE
          gp.doc_id = pm.doc_id
          AND gp.section_id = pm.section_id
          AND gp.pheno_mention_id = pm.mention_id
        """
      function: "Imply(genepheno_causation.is_correct, pheno_mentions_filtered.is_correct)"
      weight: "?"
    }

    genevariant_inference {
      input_query = """
        SELECT 
          gpr.id as "genevariant_relations.id",
          gpr.is_correct as "genevariant_relations.is_correct",
          gpf.feature as "genevariant_features.feature"
        FROM 
          genevariant_relations gpr,
          genevariant_features gpf
        WHERE 
          gpr.relation_id = gpf.relation_id;
      """
      function: IsTrue(genevariant_relations.is_correct)
      weight: "?(genevariant_features.feature)"
    }

  }

  # NOTE: the --sample_evidence flag needs the sampler binary from the sample_evidence
  # branch of the sampler repo to be in deepdive/util/; if not, just remove this flag
  sampler.sampler_args: "-l 300 -s 1 -i 500 --alpha 0.1 --diminish 0.99 --sample_evidence"
}

